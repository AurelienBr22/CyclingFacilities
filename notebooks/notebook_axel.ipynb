{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "## data gouv API call\n",
    "import requests\n",
    "\n",
    "# formating files (filenames, encodings, separators)\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import yaml\n",
    "\n",
    "#### DL, SAVE & CONCAT DATASETS ####\n",
    "def get_datasets_url(url):\n",
    "    response = requests.get(url).json()\n",
    "    return {el['title']: el['latest'] for el in response['resources'] if el['title'].endswith(\".csv\") and not el['title'].startswith(\"vehicules-immatricules\")}\n",
    "\n",
    "\n",
    "def download_and_save_datasets(url_dict, save_path):\n",
    "    for path, url in url_dict.items():\n",
    "        full_path = os.path.join(save_path, path)\n",
    "        if not os.path.exists(full_path):\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                with open(full_path, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "\n",
    "\n",
    "def rename_files(config_path, save_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        rename_config = config.get('rename')\n",
    "\n",
    "    for old_name, new_name in rename_config.items():\n",
    "        old_file_path = os.path.join(save_path, old_name)\n",
    "        new_file_path = os.path.join(save_path, new_name)\n",
    "\n",
    "        if os.path.exists(old_file_path):\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "            print(f\"Fichier renommé : {old_name} -> {new_name}\")\n",
    "        else:\n",
    "            print(f\"Fichier non trouvé : {old_name}\")\n",
    "\n",
    "def download_and_process_datasets(base_url='https://www.data.gouv.fr/api/1/datasets/53698f4ca3a729239d2036df/',\n",
    "                                  config_path='../config.yml',\n",
    "                                  save_path='../raw_data/'):\n",
    "    datasets = get_datasets_url(base_url)\n",
    "    categories = [\"lieux\", \"usagers\", \"car\", \"vehicule\"]\n",
    "\n",
    "    categorized_urls = {category: {i: j for i, j in datasets.items() if i.startswith(category)}\n",
    "                        for category in categories}\n",
    "\n",
    "    for category, url_dict in categorized_urls.items():\n",
    "        download_and_save_datasets(url_dict, save_path)\n",
    "\n",
    "    rename_files(config_path, save_path)\n",
    "\n",
    "    return categorized_urls\n",
    "\n",
    "def concat_files(starting_word):\n",
    "\n",
    "    chemin_fichier_yml = '../config.yml'\n",
    "    with open(chemin_fichier_yml, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "        config_sep = config.get('sep')\n",
    "        config_encoding = config.get('encoding')\n",
    "\n",
    "    chemin_dossier = '../raw_data/'\n",
    "\n",
    "    df_concat = pd.DataFrame()\n",
    "    files = [file for file in os.listdir(chemin_dossier) if file.endswith('.csv') and file.startswith(starting_word)]\n",
    "\n",
    "    print(files)\n",
    "    for file in files:\n",
    "        chemin_fichier = os.path.join(chemin_dossier, file)\n",
    "\n",
    "        if file in config_sep:\n",
    "            sep = config_sep[file]\n",
    "        else:\n",
    "            sep = ','\n",
    "\n",
    "        if file in config_encoding:\n",
    "            encoding = config_encoding[file]\n",
    "        else:\n",
    "            encoding = 'utf-8'\n",
    "\n",
    "        df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n",
    "\n",
    "        df_concat = pd.concat([df_concat, df1])\n",
    "\n",
    "    return df_concat\n",
    "\n",
    "#### CLEANING VEHICULES ####\n",
    "def process_catv(df):\n",
    "    df.loc[df.catv == -1, 'catv'] = df.catv.mode()[0]\n",
    "    df = df[df['catv']==1]\n",
    "    return df\n",
    "\n",
    "def create_aug(df):\n",
    "    df['aug'] = df['Num_Acc'].astype(str) + df['num_veh'].astype(str)\n",
    "    return df\n",
    "\n",
    "#### CLEANING CARACTERISTIQUES ####\n",
    "def process_dates(df, year_col='an', month_col='mois', day_col='jour', time_col='hrmn'):\n",
    "    # Checking for invalid dates\n",
    "    invalid_dates = df[(df[day_col] > 31) | ((df[month_col] == 2) & (df[day_col] > 29)) | ((df[month_col].isin([4, 6, 9, 11])) & (df[day_col] > 30))]\n",
    "    df = df.drop(invalid_dates.index)\n",
    "\n",
    "    # Creating the 'date' column\n",
    "    df['date'] = pd.to_datetime(df[year_col].astype(str).str.zfill(2)\n",
    "                                + df[month_col].astype(str).str.zfill(2)\n",
    "                                + df[day_col].astype(str).str.zfill(2)\n",
    "                                + df[time_col].astype(str).str.zfill(4),\n",
    "                                format='%y%m%d%H%M', errors='coerce')\n",
    "\n",
    "    df = df.drop(columns=[year_col, month_col, day_col, time_col])\n",
    "\n",
    "    return df\n",
    "\n",
    "def drop_nans(df, columns):\n",
    "    return df.dropna(subset=columns)\n",
    "\n",
    "def impute_invalid_values(df, columns, invalid_values):\n",
    "    for column in columns:\n",
    "        for invalid_value in invalid_values:\n",
    "            # Separate handling for NaN values\n",
    "            if pd.isna(invalid_value) or (isinstance(invalid_value, pd._libs.tslibs.nattype.NaTType) and pd.api.types.is_datetime64_any_dtype(df[column])):\n",
    "                # calculate distribution excluding NaN and other invalid values\n",
    "                distribution = df[column][~df[column].isin(invalid_values)].value_counts(normalize=True)\n",
    "\n",
    "                # assign new values\n",
    "                new_values = np.random.choice(distribution.index, size=df[column].isna().sum(), p=distribution.values)\n",
    "                df.loc[df[column].isna(), column] = new_values\n",
    "            else:\n",
    "                # calculate distribution for a given value, excluding other invalid values\n",
    "                distribution = df[column][~df[column].isin(invalid_values)].value_counts(normalize=True)\n",
    "\n",
    "                # assign new values\n",
    "                new_values = np.random.choice(distribution.index, size=(df[column] == invalid_value).sum(), p=distribution.values)\n",
    "                df.loc[df[column] == invalid_value, column] = new_values\n",
    "    return df\n",
    "\n",
    "def replace_with_most_frequent(df, columns, invalid_value=-1):\n",
    "    for column in columns:\n",
    "        most_frequent = df[column].mode()[0]\n",
    "        df[column] = df[column].replace(invalid_value, most_frequent)\n",
    "    return df\n",
    "\n",
    "def filter_df_on_column(df, column, valid_values):\n",
    "    return df.loc[df[column].isin(valid_values)]\n",
    "\n",
    "#### CLEANING LIEUX ###\n",
    "def clean_column(df, column, replace_dict, fill_value):\n",
    "    df[column] = df[column].replace(replace_dict)\n",
    "    df[column].fillna(fill_value, inplace=True)\n",
    "    return df\n",
    "\n",
    "def clean_nbv(df):\n",
    "    df['nbv'] = pd.to_numeric(df['nbv'], errors='coerce')\n",
    "    df = clean_column(df, 'nbv', {-1: 2}, 2)\n",
    "    df['nbv'] = df['nbv'].where(df['nbv'] <= 10, 2)\n",
    "    return df\n",
    "\n",
    "def clean_catr(df):\n",
    "    df['catr'].fillna(4, inplace=True)\n",
    "    return df\n",
    "\n",
    "#### CLEANING USAGERS ####\n",
    "def process_grav_sexe(df, column):\n",
    "    df[column] = df[column].replace({-1: 1}).fillna(1)\n",
    "    return df\n",
    "\n",
    "def process_secu(df):\n",
    "    df['secu'].fillna(df['secu1'], inplace=True)\n",
    "    df['secu'] = df['secu'].where(df['secu'] <= 0, 1)\n",
    "    return df\n",
    "\n",
    "def process_actp(df):\n",
    "    df['actp'] = pd.to_numeric(df['actp'], errors='coerce').fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "def process_locp_etatp(df, columns):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].replace({-1: 0}).fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "def process_an_nais(df):\n",
    "    df.dropna(subset=['an_nais'], inplace=True)\n",
    "    mean_an_nais = df['an_nais'].mean()\n",
    "    df['an_nais'] = df['an_nais'].replace({0: mean_an_nais})\n",
    "    return df\n",
    "\n",
    "def drop_irrelevant_columns(df, columns):\n",
    "    return df.drop(columns=columns)\n",
    "\n",
    "def process_trajet(df):\n",
    "    trajet_impute = df['trajet'].fillna(5)\n",
    "    distribution = trajet_impute[~trajet_impute.isin([0, -1])].value_counts(normalize=True)\n",
    "    missing_values = trajet_impute.isin([0, -1])\n",
    "    trajet_impute[missing_values] = np.random.choice(distribution.index, size=missing_values.sum(), p=distribution.values)\n",
    "    df['trajet'] = trajet_impute.astype(int).replace({-1: 1})\n",
    "    return df\n",
    "\n",
    "def create_dup_count(df):\n",
    "    df['dup_count'] = df.groupby('aug')['aug'].transform('count')\n",
    "    df = df.drop_duplicates(subset=['aug'], keep='first')\n",
    "    return df\n",
    "\n",
    "def concat_datasets():\n",
    "    # concat datasets\n",
    "    carac_df = concat_files(\"caracteristiques\")\n",
    "    lieux_df = concat_files(\"lieux\")\n",
    "    usager_df = concat_files(\"usagers\")\n",
    "    vehi_df = concat_files(\"vehicules\")\n",
    "    return vehi_df, carac_df, lieux_df, usager_df\n",
    "\n",
    "def clean_datasets(vehi_df, carac_df, lieux_df, usager_df):\n",
    "    # clean vehicules\n",
    "    vehi_df_clean = (vehi_df\n",
    "                    .pipe(drop_irrelevant_columns, [\"id_vehicule\", \"motor\", \"occutc\", \"senc\"])\n",
    "                    .pipe(process_catv)\n",
    "                    .pipe(create_aug)\n",
    "                    .pipe(impute_invalid_values, ['obs', 'obsm', 'choc', 'manv'], [-1, np.NaN]))\n",
    "\n",
    "    # clean caracteristiques\n",
    "    carac_df_clean = (carac_df\n",
    "                    .pipe(drop_irrelevant_columns, ['gps', 'Accident_Id'])\n",
    "                    .pipe(process_dates)\n",
    "                    .pipe(impute_invalid_values, ['date', 'atm'], [np.NaN])\n",
    "                    .pipe(drop_nans, ['Num_Acc', 'col', 'com'])\n",
    "                    .pipe(impute_invalid_values, ['lum', 'int', 'col'], [-1])\n",
    "                    .pipe(replace_with_most_frequent, ['lum', 'agg', 'atm']))\n",
    "\n",
    "    # clean lieux\n",
    "    lieux_df_clean = (lieux_df\n",
    "                    .pipe(clean_column, 'situ', {-1: 1, 0: 1}, 1)\n",
    "                    .pipe(clean_column, 'circ', {0: 2, -1: 2}, 2)\n",
    "                    .pipe(clean_nbv)\n",
    "                    .pipe(clean_column, 'vosp', {-1: 0}, 0)\n",
    "                    .pipe(clean_column, 'prof', {-1: 1, 0: 1}, 1)\n",
    "                    .pipe(clean_column, 'plan', {-1: 1, 0: 1}, 1)\n",
    "                    .pipe(clean_column, 'surf', {-1: 1, 0: 1, 9: 1}, 1)\n",
    "                    .pipe(clean_column, 'infra', {-1: 1}, 1)\n",
    "                    .pipe(clean_catr)\n",
    "                    .pipe(drop_irrelevant_columns, ['voie', 'v1', 'v2', 'pr', 'pr1', 'lartpc', 'larrout', 'vma', 'env1']))\n",
    "\n",
    "    # clean usagers\n",
    "    usager_df_clean = (usager_df\n",
    "                    .pipe(process_grav_sexe, column='grav')\n",
    "                    .pipe(process_grav_sexe, column='sexe')\n",
    "                    .pipe(process_trajet)\n",
    "                    .pipe(process_secu)\n",
    "                    .pipe(process_actp)\n",
    "                    .pipe(process_locp_etatp, columns=['locp', 'etatp'])\n",
    "                    .pipe(process_an_nais)\n",
    "                    .pipe(create_aug)\n",
    "                    .pipe(create_dup_count)\n",
    "                    .pipe(drop_irrelevant_columns, columns=['place', 'catu', 'secu1', 'secu2', 'secu3', 'num_veh', 'id_vehicule', 'id_usager']))\n",
    "\n",
    "    return vehi_df_clean, carac_df_clean, lieux_df_clean, usager_df_clean\n",
    "\n",
    "def merge_cleaned_datasets(vehi_df_clean, carac_df_clean, lieux_df_clean, usager_df_clean):\n",
    "    vehi_usa = pd.merge(vehi_df_clean, usager_df_clean, on='aug', how='inner')\n",
    "    vehi_usa = vehi_usa.drop(columns=['num_veh', 'Num_Acc_y'])\n",
    "    vehi_usa = vehi_usa.rename(columns={'Num_Acc_x': 'Num_Acc'})\n",
    "\n",
    "    duplicates_velo = vehi_usa[vehi_usa['Num_Acc'].duplicated(keep=False)]\n",
    "\n",
    "    velo_df = pd.merge(vehi_usa, lieux_df_clean, on='Num_Acc', how='left')\n",
    "    all_datasets = pd.merge(velo_df, carac_df_clean, on='Num_Acc', how='left')\n",
    "\n",
    "    return all_datasets, duplicates_velo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Acc</th>\n",
       "      <th>senc</th>\n",
       "      <th>catv</th>\n",
       "      <th>occutc</th>\n",
       "      <th>obs</th>\n",
       "      <th>obsm</th>\n",
       "      <th>choc</th>\n",
       "      <th>manv</th>\n",
       "      <th>num_veh</th>\n",
       "      <th>id_vehicule</th>\n",
       "      <th>motor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200500000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200500000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>B02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200500000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>A01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200500000002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200500000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105809</th>\n",
       "      <td>201200062248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>A01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105810</th>\n",
       "      <td>201200062249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105811</th>\n",
       "      <td>201200062249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105812</th>\n",
       "      <td>201200062249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>C01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105813</th>\n",
       "      <td>201200062250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2009395 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Num_Acc  senc  catv  occutc   obs  obsm  choc  manv num_veh  \\\n",
       "0       200500000001   0.0     7     0.0   0.0   2.0   1.0   1.0     A01   \n",
       "1       200500000001   0.0     7     0.0   0.0   2.0   8.0  10.0     B02   \n",
       "2       200500000002   0.0     7     0.0   0.0   2.0   7.0  16.0     A01   \n",
       "3       200500000002   0.0     2     0.0   0.0   2.0   1.0   1.0     B02   \n",
       "4       200500000003   0.0     2     0.0   0.0   2.0   1.0   1.0     A01   \n",
       "...              ...   ...   ...     ...   ...   ...   ...   ...     ...   \n",
       "105809  201200062248   0.0    30     0.0   0.0   2.0   7.0  15.0     A01   \n",
       "105810  201200062249   0.0     1     0.0   0.0   2.0   4.0   1.0     B01   \n",
       "105811  201200062249   0.0     1     0.0   0.0   2.0   4.0   1.0     A01   \n",
       "105812  201200062249   0.0     2     0.0   0.0   2.0   1.0   1.0     C01   \n",
       "105813  201200062250   0.0     7     0.0  16.0   0.0   1.0   1.0     A01   \n",
       "\n",
       "       id_vehicule  motor  \n",
       "0              NaN    NaN  \n",
       "1              NaN    NaN  \n",
       "2              NaN    NaN  \n",
       "3              NaN    NaN  \n",
       "4              NaN    NaN  \n",
       "...            ...    ...  \n",
       "105809         NaN    NaN  \n",
       "105810         NaN    NaN  \n",
       "105811         NaN    NaN  \n",
       "105812         NaN    NaN  \n",
       "105813         NaN    NaN  \n",
       "\n",
       "[2009395 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier renommé : caracteristiques-2017.csv -> caracteristiques_2017.csv\n",
      "Fichier renommé : caracteristiques-2018.csv -> caracteristiques_2018.csv\n",
      "Fichier renommé : caracteristiques-2019.csv -> caracteristiques_2019.csv\n",
      "Fichier renommé : caracteristiques-2020.csv -> caracteristiques_2020.csv\n",
      "Fichier renommé : carcteristiques-2021.csv -> caracteristiques_2021.csv\n",
      "Fichier renommé : carcteristiques-2022.csv -> caracteristiques_2022.csv\n",
      "Fichier renommé : lieux-2017.csv -> lieux_2017.csv\n",
      "Fichier renommé : lieux-2018.csv -> lieux_2018.csv\n",
      "Fichier renommé : lieux-2019.csv -> lieux_2019.csv\n",
      "Fichier renommé : lieux-2020.csv -> lieux_2020.csv\n",
      "Fichier renommé : lieux-2021.csv -> lieux_2021.csv\n",
      "Fichier renommé : lieux-2022.csv -> lieux_2022.csv\n",
      "Fichier renommé : usagers-2017.csv -> usagers_2017.csv\n",
      "Fichier renommé : usagers-2018.csv -> usagers_2018.csv\n",
      "Fichier renommé : usagers-2019.csv -> usagers_2019.csv\n",
      "Fichier renommé : usagers-2020.csv -> usagers_2020.csv\n",
      "Fichier renommé : usagers-2021.csv -> usagers_2021.csv\n",
      "Fichier renommé : usagers-2022.csv -> usagers_2022.csv\n",
      "Fichier renommé : vehicules-2017.csv -> vehicules_2017.csv\n",
      "Fichier renommé : vehicules-2018.csv -> vehicules_2018.csv\n",
      "Fichier renommé : vehicules-2019.csv -> vehicules_2019.csv\n",
      "Fichier renommé : vehicules-2020.csv -> vehicules_2020.csv\n",
      "Fichier renommé : vehicules-2021.csv -> vehicules_2021.csv\n",
      "Fichier renommé : vehicules-2022.csv -> vehicules_2022.csv\n",
      "['caracteristiques_2006.csv', 'caracteristiques_2016.csv', 'caracteristiques_2020.csv', 'caracteristiques_2008.csv', 'caracteristiques_2022.csv', 'caracteristiques_2012.csv', 'caracteristiques_2007.csv', 'caracteristiques_2011.csv', 'caracteristiques_2021.csv', 'caracteristiques_2013.csv', 'caracteristiques_2014.csv', 'caracteristiques_2009.csv', 'caracteristiques_2017.csv', 'caracteristiques_2019.csv', 'caracteristiques_2018.csv', 'caracteristiques_2010.csv', 'caracteristiques_2015.csv', 'caracteristiques_2005.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62300/600514303.py:81: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lieux_2015.csv', 'lieux_2010.csv', 'lieux_2005.csv', 'lieux_2019.csv', 'lieux_2008.csv', 'lieux_2011.csv', 'lieux_2006.csv', 'lieux_2017.csv', 'lieux_2018.csv', 'lieux_2014.csv', 'lieux_2022.csv', 'lieux_2009.csv', 'lieux_2007.csv', 'lieux_2020.csv', 'lieux_2021.csv', 'lieux_2013.csv', 'lieux_2012.csv', 'lieux_2016.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62300/600514303.py:81: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n",
      "/tmp/ipykernel_62300/600514303.py:81: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n",
      "/tmp/ipykernel_62300/600514303.py:81: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n",
      "/tmp/ipykernel_62300/600514303.py:81: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['usagers_2006.csv', 'usagers_2021.csv', 'usagers_2020.csv', 'usagers_2014.csv', 'usagers_2010.csv', 'usagers_2007.csv', 'usagers_2005.csv', 'usagers_2018.csv', 'usagers_2019.csv', 'usagers_2016.csv', 'usagers_2017.csv', 'usagers_2022.csv', 'usagers_2008.csv', 'usagers_2009.csv', 'usagers_2013.csv', 'usagers_2015.csv', 'usagers_2011.csv', 'usagers_2012.csv']\n",
      "['vehicules_2005.csv', 'vehicules_2018.csv', 'vehicules_2011.csv', 'vehicules_2013.csv', 'vehicules_2017.csv', 'vehicules_2006.csv', 'vehicules_2016.csv', 'vehicules_2020.csv', 'vehicules_2008.csv', 'vehicules_2014.csv', 'vehicules_2009.csv', 'vehicules_2022.csv', 'vehicules_2007.csv', 'vehicules_2021.csv', 'vehicules_2019.csv', 'vehicules_2015.csv', 'vehicules_2010.csv', 'vehicules_2012.csv']\n"
     ]
    }
   ],
   "source": [
    "download_and_process_datasets()\n",
    "vehi_df, carac_df, lieux_df, usager_df = concat_datasets()\n",
    "vehi_df_clean, carac_df_clean, lieux_df_clean, usager_df_clean = clean_datasets(vehi_df, carac_df, lieux_df, usager_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Acc</th>\n",
       "      <th>catv</th>\n",
       "      <th>obs</th>\n",
       "      <th>obsm</th>\n",
       "      <th>choc</th>\n",
       "      <th>manv</th>\n",
       "      <th>aug</th>\n",
       "      <th>grav</th>\n",
       "      <th>sexe</th>\n",
       "      <th>trajet</th>\n",
       "      <th>...</th>\n",
       "      <th>agg</th>\n",
       "      <th>int</th>\n",
       "      <th>atm</th>\n",
       "      <th>col</th>\n",
       "      <th>com</th>\n",
       "      <th>adr</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>dep</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200500000030</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>200500000030B02</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>rue de la chapelle</td>\n",
       "      <td>5030000.0</td>\n",
       "      <td>284000.0</td>\n",
       "      <td>620</td>\n",
       "      <td>2005-01-13 19:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200500000034</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200500000034B02</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>620</td>\n",
       "      <td>2005-01-19 10:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200500000078</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200500000078B02</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2005-01-26 13:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200500000093</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>200500000093B02</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>rue du grand montoir</td>\n",
       "      <td>4925500.0</td>\n",
       "      <td>309400.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2005-01-03 13:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200500000170</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>200500000170A01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>760</td>\n",
       "      <td>2005-01-29 18:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88516</th>\n",
       "      <td>201200062214</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201200062214B01</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16</td>\n",
       "      <td>74, HIPPOLYTE  PIOT(RUE)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>2012-10-31 20:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88517</th>\n",
       "      <td>201200062217</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201200062217B01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16</td>\n",
       "      <td>NEANT, CHATEAU D'EAU (AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>2012-11-05 15:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88518</th>\n",
       "      <td>201200062230</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201200062230A01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16</td>\n",
       "      <td>SANS, ENTRE DEUX (CHEMIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>2012-11-18 07:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88519</th>\n",
       "      <td>201200062249</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201200062249B01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16</td>\n",
       "      <td>SANS, RN1 (ROUTE NATIONA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>2012-12-23 06:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88520</th>\n",
       "      <td>201200062249</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201200062249A01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16</td>\n",
       "      <td>SANS, RN1 (ROUTE NATIONA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>2012-12-23 06:20:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88521 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Num_Acc  catv  obs  obsm  choc  manv              aug  grav  sexe  \\\n",
       "0      200500000030     1  0.0   2.0   8.0  11.0  200500000030B02     4     1   \n",
       "1      200500000034     1  0.0   2.0   1.0   1.0  200500000034B02     3     1   \n",
       "2      200500000078     1  0.0   2.0   1.0   1.0  200500000078B02     4     1   \n",
       "3      200500000093     1  0.0   2.0   3.0  21.0  200500000093B02     3     2   \n",
       "4      200500000170     1  0.0   2.0   4.0   2.0  200500000170A01     4     1   \n",
       "...             ...   ...  ...   ...   ...   ...              ...   ...   ...   \n",
       "88516  201200062214     1  0.0   2.0   1.0   1.0  201200062214B01     4     2   \n",
       "88517  201200062217     1  0.0   0.0   8.0   1.0  201200062217B01     4     1   \n",
       "88518  201200062230     1  0.0   2.0   3.0   1.0  201200062230A01     4     1   \n",
       "88519  201200062249     1  0.0   2.0   4.0   1.0  201200062249B01     3     1   \n",
       "88520  201200062249     1  0.0   2.0   4.0   1.0  201200062249A01     3     1   \n",
       "\n",
       "       trajet  ...  agg  int  atm  col    com                       adr  \\\n",
       "0           5  ...  2.0  1.0  1.0  3.0  331.0        rue de la chapelle   \n",
       "1           5  ...  1.0  1.0  7.0  1.0   22.0                       NaN   \n",
       "2           5  ...  1.0  9.0  1.0  3.0  173.0                       NaN   \n",
       "3           4  ...  2.0  1.0  1.0  1.0  810.0      rue du grand montoir   \n",
       "4           5  ...  1.0  1.0  1.0  2.0  196.0                       NaN   \n",
       "...       ...  ...  ...  ...  ...  ...    ...                       ...   \n",
       "88516       5  ...  2.0  1.0  1.0  3.0     16  74, HIPPOLYTE  PIOT(RUE)   \n",
       "88517       9  ...  2.0  1.0  1.0  3.0     16  NEANT, CHATEAU D'EAU (AL   \n",
       "88518       5  ...  2.0  1.0  1.0  3.0     16  SANS, ENTRE DEUX (CHEMIN   \n",
       "88519       9  ...  1.0  1.0  1.0  4.0     16  SANS, RN1 (ROUTE NATIONA   \n",
       "88520       5  ...  1.0  1.0  1.0  4.0     16  SANS, RN1 (ROUTE NATIONA   \n",
       "\n",
       "             lat      long  dep                date  \n",
       "0      5030000.0  284000.0  620 2005-01-13 19:45:00  \n",
       "1            0.0       0.0  620 2005-01-19 10:45:00  \n",
       "2            0.0       0.0   20 2005-01-26 13:15:00  \n",
       "3      4925500.0  309400.0   20 2005-01-03 13:30:00  \n",
       "4            0.0       0.0  760 2005-01-29 18:30:00  \n",
       "...          ...       ...  ...                 ...  \n",
       "88516        NaN       NaN  974 2012-10-31 20:50:00  \n",
       "88517        NaN       NaN  974 2012-11-05 15:15:00  \n",
       "88518        NaN       NaN  974 2012-11-18 07:15:00  \n",
       "88519        NaN       NaN  974 2012-12-23 06:20:00  \n",
       "88520        NaN       NaN  974 2012-12-23 06:20:00  \n",
       "\n",
       "[88521 rows x 36 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_datasets, duplicates_velo = merge_cleaned_datasets(vehi_df_clean, carac_df_clean, lieux_df_clean, usager_df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lum      5291\n",
       "agg      5291\n",
       "int      5291\n",
       "atm      5291\n",
       "col      5291\n",
       "com      5291\n",
       "adr     11542\n",
       "lat     40603\n",
       "long    40603\n",
       "dep      5291\n",
       "date     5291\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_datasets.isna().sum()[all_datasets.isna().sum() > 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Acc</th>\n",
       "      <th>lum</th>\n",
       "      <th>agg</th>\n",
       "      <th>int</th>\n",
       "      <th>atm</th>\n",
       "      <th>col</th>\n",
       "      <th>com</th>\n",
       "      <th>adr</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>dep</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.006000e+11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53</td>\n",
       "      <td>SANS N°, PONT DES CHEVRE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2006-01-04 15:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.006000e+11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53</td>\n",
       "      <td>BROU ( BD DU N° 47 A 65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2006-01-06 08:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.006000e+11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>53</td>\n",
       "      <td>sans, CLAVAGRY ( RUE)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2006-01-09 13:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.006000e+11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53</td>\n",
       "      <td>23EME R.I. ( RUE DU)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2006-01-10 16:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.006000e+11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53</td>\n",
       "      <td>MARBOZ (AVENUEDE - IMPAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2006-01-24 11:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87021</th>\n",
       "      <td>2.005001e+11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>sans, LEBLOND(RUE M. ET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>2005-12-21 20:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87022</th>\n",
       "      <td>2.005001e+11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>SANS, PRESIDENT MITTERAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>2005-12-23 10:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87023</th>\n",
       "      <td>2.005001e+11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>SANS, LEBLOND(RUE M. ET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>2005-12-26 17:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87024</th>\n",
       "      <td>2.005001e+11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>SANS, HUBERT DE LISLE(BO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>2005-12-27 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87025</th>\n",
       "      <td>2.005001e+11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>RN01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974</td>\n",
       "      <td>2005-12-31 21:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1121482 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Num_Acc  lum  agg  int  atm  col    com                       adr  \\\n",
       "0      2.006000e+11    1    2    2  1.0  3.0     53  SANS N°, PONT DES CHEVRE   \n",
       "1      2.006000e+11    2    2    2  4.0  3.0     53   BROU ( BD DU N° 47 A 65   \n",
       "2      2.006000e+11    1    2    1  1.0  6.0     53     sans, CLAVAGRY ( RUE)   \n",
       "3      2.006000e+11    2    2    1  8.0  3.0     53      23EME R.I. ( RUE DU)   \n",
       "4      2.006000e+11    1    1    1  1.0  2.0     53  MARBOZ (AVENUEDE - IMPAI   \n",
       "...             ...  ...  ...  ...  ...  ...    ...                       ...   \n",
       "87021  2.005001e+11    5    2    2  1.0  3.0  416.0   sans, LEBLOND(RUE M. ET   \n",
       "87022  2.005001e+11    1    2    1  1.0  3.0  416.0  SANS, PRESIDENT MITTERAN   \n",
       "87023  2.005001e+11    1    2    2  1.0  3.0  416.0   SANS, LEBLOND(RUE M. ET   \n",
       "87024  2.005001e+11    1    2    3  2.0  5.0  416.0  SANS, HUBERT DE LISLE(BO   \n",
       "87025  2.005001e+11    5    2    1  2.0  7.0  414.0                      RN01   \n",
       "\n",
       "       lat long  dep                date  \n",
       "0      NaN  NaN   10 2006-01-04 15:45:00  \n",
       "1      NaN  NaN   10 2006-01-06 08:05:00  \n",
       "2      NaN  NaN   10 2006-01-09 13:40:00  \n",
       "3      NaN  NaN   10 2006-01-10 16:25:00  \n",
       "4      NaN  NaN   10 2006-01-24 11:20:00  \n",
       "...    ...  ...  ...                 ...  \n",
       "87021  NaN  NaN  974 2005-12-21 20:35:00  \n",
       "87022  NaN  NaN  974 2005-12-23 10:10:00  \n",
       "87023  NaN  NaN  974 2005-12-26 17:15:00  \n",
       "87024  NaN  NaN  974 2005-12-27 15:00:00  \n",
       "87025  NaN  NaN  974 2005-12-31 21:00:00  \n",
       "\n",
       "[1121482 rows x 12 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# catv_group_named = {\n",
    "#     \"Bicycles_ElectricScooters\": [1, 80, 50, 60],  # Bicycles, E-bikes, and Personal Mobility Devices\n",
    "#     \"Cars\": [3, 7, 8, 9],  # Cars including light vehicles, VL + caravane, VL + remorque\n",
    "#     \"Motorcycles_Scooters\": [2, 30, 31, 32, 33, 34, 41, 42, 43, 4, 5, 6],  # Motorcycles, scooters, scooter immatriculé, motocyclette, side-car\n",
    "#     \"HeavyVehicles_Buses\": [10, 13, 14, 15, 16, 17, 37, 38, 18, 19],  # Utility vehicles, heavy trucks, buses, transport en commun, tramway\n",
    "#     \"Others_SpecialVehicles\": [0, 20, 21, 39, 40, 99, 11, 12, 35, 36]  # Special vehicles and others, VU + caravane, VU + remorque\n",
    "# }\n",
    "\n",
    "\n",
    "# obs_group_named = {\n",
    "#     \"NoObstacle\": [-1, 0],  # Without obstacle\n",
    "#     \"WithObstacle\": list(range(1, 18))  # With obstacle\n",
    "# }\n",
    "\n",
    "# obsm_group_named = {\n",
    "#     \"Pedestrian_Vehicle_Rail\": [1, 2, 4],  # Pedestrian, Vehicle, Rail Vehicle\n",
    "#     \"Animals\": [5, 6],  # Animals\n",
    "#     \"Others_NotClassified\": [-1, 0, 9]  # Other or Not Classified\n",
    "# }\n",
    "\n",
    "# choc_group_named = {\n",
    "#     \"NoImpact\": [0],  # No impact\n",
    "#     \"Impact\": list(range(1, 10))  # Impact\n",
    "# }\n",
    "\n",
    "# manv_group_named = {\n",
    "#     \"BasicManeuvers\": [1, 2, 3],  # Standard driving maneuvers\n",
    "#     \"DirectionalChanges\": [11, 12, 13, 14, 15, 16, 17, 18],  # Maneuvers involving directional changes\n",
    "#     \"DefensiveManeuvers\": [21, 22],  # Defensive driving maneuvers\n",
    "#     \"TrajectoryChanges\": [10],  # Significant trajectory changes\n",
    "#     \"RiskyManeuvers\": [4, 5, 6, 7, 8, 9, 19, 26],  # Unusual or risky maneuvers\n",
    "#     \"StationaryParkingManeuvers\": [20, 23, 24, 25]  # Stationary or parking related maneuvers\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Acc</th>\n",
       "      <th>grav</th>\n",
       "      <th>sexe</th>\n",
       "      <th>trajet</th>\n",
       "      <th>secu</th>\n",
       "      <th>locp</th>\n",
       "      <th>actp</th>\n",
       "      <th>etatp</th>\n",
       "      <th>an_nais</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200600000001</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200600000001</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200600000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200600000002</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1972.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200600000002</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138623</th>\n",
       "      <td>201200062248</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138624</th>\n",
       "      <td>201200062249</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138625</th>\n",
       "      <td>201200062249</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1957.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138626</th>\n",
       "      <td>201200062249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1991.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138627</th>\n",
       "      <td>201200062250</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2628018 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Num_Acc  grav  sexe  trajet  secu  locp  actp  etatp  an_nais\n",
       "0       200600000001     4     1       5   1.0     0     0      0   1949.0\n",
       "1       200600000001     4     2       5   1.0     0     0      0   1948.0\n",
       "2       200600000001     1     2       5   1.0     0     0      0   1921.0\n",
       "3       200600000002     4     2       1   1.0     0     0      0   1972.0\n",
       "4       200600000002     4     2       2   1.0     0     0      0   1984.0\n",
       "...              ...   ...   ...     ...   ...   ...   ...    ...      ...\n",
       "138623  201200062248     4     1       5   1.0     0     0      0   1994.0\n",
       "138624  201200062249     3     1       9   1.0     0     0      0   1987.0\n",
       "138625  201200062249     3     1       5   1.0     0     0      0   1957.0\n",
       "138626  201200062249     1     1       9   1.0     0     0      0   1991.0\n",
       "138627  201200062250     4     2       9   1.0     0     0      0   1984.0\n",
       "\n",
       "[2628018 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création d'une colonne uniques pour merger les df usagers et véhicules\n",
    "# usagers_df['aug'] = usagers_df['Num_Acc'].astype(str) + usagers_df['num_veh'].astype(str)\n",
    "# vehicules_df['aug'] = vehicules_df['Num_Acc'].astype(str) + vehicules_df['num_veh'].astype(str)\n",
    "\n",
    "# vehicules_df.shape\n",
    "# vehicules_df = vehicules_df[vehicules_df['catv']==1]\n",
    "\n",
    "\n",
    "# On drop les duplicates lorsqu'il y a une plusieurs usagers dans un même véhicules et pour le même accident\n",
    "# On crée une colonne pour y ajouter le nombre d'usagers par véhicules\n",
    "\n",
    "\n",
    "# usagers_df['dup_count'] = usagers_df.groupby('aug')['aug'].transform('count')\n",
    "# usagers_df = usagers_df.drop_duplicates(subset=['aug'], keep='first')\n",
    "\n",
    "# On merge véhicules et usagers puis on ne garde que les accidents impliquant un vélo\n",
    "# On clean et on drop les doublons\n",
    "\n",
    "vehi_usa = pd.merge(vehicules_df, usagers_df, on='aug', how='inner')\n",
    "vehi_usa = vehi_usa.drop(columns=['num_veh_x', 'num_veh_y', 'Num_Acc_y'])\n",
    "vehi_usa = vehi_usa.rename(columns={'Num_Acc_x': 'Num_Acc'})\n",
    "\n",
    "duplicates_velo = vehi_usa[vehi_usa['Num_Acc'].duplicated(keep=False)]\n",
    "duplicates_velo.info()\n",
    "\n",
    "velo_df = pd.merge(vehi_usa, lieux_df, on='Num_Acc', how='left')\n",
    "velo_df = pd.merge(velo_df, caracteristiques_df, on='Num_Acc', how='left')\n",
    "\n",
    "\n",
    "\n",
    "# On remplace les valeurs manquantes par la valeur la plus fréquente\n",
    "velo_df['lum'].fillna(velo_df['lum'].mode()[0], inplace=True)\n",
    "velo_df['agg'].fillna(velo_df['agg'].mode()[0], inplace=True)\n",
    "velo_df['atm'].fillna(velo_df['atm'].mode()[0], inplace=True)\n",
    "velo_df['atm'] = velo_df['atm'].replace({ -1: 1, 9: 1})\n",
    "\n",
    "\n",
    "# # Obtenez la distribution des valeurs\n",
    "# distribution = velo_df['int'].value_counts(normalize=True)\n",
    "# # Obtenez les valeurs manquantes\n",
    "# missing = velo_df['int'].isnull()\n",
    "# # Remplissez les valeurs manquantes en fonction de la distribution\n",
    "# velo_df.loc[missing, 'int'] = np.random.choice(distribution.index, size=len(velo_df[missing]), p=distribution.values)\n",
    "\n",
    "# # Obtenez la distribution des valeurs\n",
    "# distribution = velo_df['col'].value_counts(normalize=True)\n",
    "# # Obtenez les valeurs manquantes\n",
    "# missing = velo_df['col'].isnull()\n",
    "# # Remplissez les valeurs manquantes en fonction de la distribution\n",
    "# velo_df.loc[missing, 'col'] = np.random.choice(distribution.index, size=len(velo_df[missing]), p=distribution.values)\n",
    "# Je remplace le -1 par 1\n",
    "velo_df['col'] = velo_df['col'].replace({ -1: 3})\n",
    "\n",
    "velo_df = velo_df[~(velo_df.adr.isna() & velo_df.lat.isna() & velo_df.long.isna() & velo_df.com.isna() & velo_df.dep.isna())]\n",
    "\n",
    "# Réinitialisez l'index de votre DataFrame\n",
    "velo_df = velo_df.reset_index(drop=True)\n",
    "\n",
    "# Obtenez la distribution des valeurs\n",
    "distribution = velo_df['date'].value_counts(normalize=True)\n",
    "\n",
    "# Obtenez les valeurs manquantes\n",
    "missing = velo_df['date'].isnull()\n",
    "\n",
    "# Remplissez les valeurs manquantes en fonction de la distribution\n",
    "velo_df.loc[missing, 'date'] = np.random.choice(distribution.index, size=len(velo_df[missing]), p=distribution.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier renommé : caracteristiques-2017.csv -> caracteristiques_2017.csv\n",
      "Fichier renommé : caracteristiques-2018.csv -> caracteristiques_2018.csv\n",
      "Fichier renommé : caracteristiques-2019.csv -> caracteristiques_2019.csv\n",
      "Fichier renommé : caracteristiques-2020.csv -> caracteristiques_2020.csv\n",
      "Fichier renommé : carcteristiques-2021.csv -> caracteristiques_2021.csv\n",
      "Fichier renommé : carcteristiques-2022.csv -> caracteristiques_2022.csv\n",
      "Fichier renommé : lieux-2017.csv -> lieux_2017.csv\n",
      "Fichier renommé : lieux-2018.csv -> lieux_2018.csv\n",
      "Fichier renommé : lieux-2019.csv -> lieux_2019.csv\n",
      "Fichier renommé : lieux-2020.csv -> lieux_2020.csv\n",
      "Fichier renommé : lieux-2021.csv -> lieux_2021.csv\n",
      "Fichier renommé : lieux-2022.csv -> lieux_2022.csv\n",
      "Fichier renommé : usagers-2017.csv -> usagers_2017.csv\n",
      "Fichier renommé : usagers-2018.csv -> usagers_2018.csv\n",
      "Fichier renommé : usagers-2019.csv -> usagers_2019.csv\n",
      "Fichier renommé : usagers-2020.csv -> usagers_2020.csv\n",
      "Fichier renommé : usagers-2021.csv -> usagers_2021.csv\n",
      "Fichier renommé : usagers-2022.csv -> usagers_2022.csv\n",
      "Fichier renommé : vehicules-2017.csv -> vehicules_2017.csv\n",
      "Fichier renommé : vehicules-2018.csv -> vehicules_2018.csv\n",
      "Fichier renommé : vehicules-2019.csv -> vehicules_2019.csv\n",
      "Fichier renommé : vehicules-2020.csv -> vehicules_2020.csv\n",
      "Fichier renommé : vehicules-2021.csv -> vehicules_2021.csv\n",
      "Fichier renommé : vehicules-2022.csv -> vehicules_2022.csv\n",
      "['caracteristiques_2006.csv', 'caracteristiques_2016.csv', 'caracteristiques_2020.csv', 'caracteristiques_2008.csv', 'caracteristiques_2022.csv', 'caracteristiques_2012.csv', 'caracteristiques_2007.csv', 'caracteristiques_2011.csv', 'caracteristiques_2021.csv', 'caracteristiques_2013.csv', 'caracteristiques_2014.csv', 'caracteristiques_2009.csv', 'caracteristiques_2017.csv', 'caracteristiques_2019.csv', 'caracteristiques_2018.csv', 'caracteristiques_2010.csv', 'caracteristiques_2015.csv', 'caracteristiques_2005.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58703/777589952.py:75: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lieux_2015.csv', 'lieux_2010.csv', 'lieux_2005.csv', 'lieux_2019.csv', 'lieux_2008.csv', 'lieux_2011.csv', 'lieux_2006.csv', 'lieux_2017.csv', 'lieux_2018.csv', 'lieux_2014.csv', 'lieux_2022.csv', 'lieux_2009.csv', 'lieux_2007.csv', 'lieux_2020.csv', 'lieux_2021.csv', 'lieux_2013.csv', 'lieux_2012.csv', 'lieux_2016.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58703/777589952.py:75: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n",
      "/tmp/ipykernel_58703/777589952.py:75: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n",
      "/tmp/ipykernel_58703/777589952.py:75: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n",
      "/tmp/ipykernel_58703/777589952.py:75: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['usagers_2006.csv', 'usagers_2021.csv', 'usagers_2020.csv', 'usagers_2014.csv', 'usagers_2010.csv', 'usagers_2007.csv', 'usagers_2005.csv', 'usagers_2018.csv', 'usagers_2019.csv', 'usagers_2016.csv', 'usagers_2017.csv', 'usagers_2022.csv', 'usagers_2008.csv', 'usagers_2009.csv', 'usagers_2013.csv', 'usagers_2015.csv', 'usagers_2011.csv', 'usagers_2012.csv']\n",
      "['vehicules_2005.csv', 'vehicules_2018.csv', 'vehicules_2011.csv', 'vehicules_2013.csv', 'vehicules_2017.csv', 'vehicules_2006.csv', 'vehicules_2016.csv', 'vehicules_2020.csv', 'vehicules_2008.csv', 'vehicules_2014.csv', 'vehicules_2009.csv', 'vehicules_2022.csv', 'vehicules_2007.csv', 'vehicules_2021.csv', 'vehicules_2019.csv', 'vehicules_2015.csv', 'vehicules_2010.csv', 'vehicules_2012.csv']\n"
     ]
    }
   ],
   "source": [
    "def get_datasets_url(url):\n",
    "    response = requests.get(url).json()\n",
    "    return {el['title']: el['latest'] for el in response['resources'] if el['title'].endswith(\".csv\") and not el['title'].startswith(\"vehicules-immatricules\")}\n",
    "\n",
    "\n",
    "def download_and_save_datasets(url_dict, save_path):\n",
    "    for path, url in url_dict.items():\n",
    "        full_path = os.path.join(save_path, path)\n",
    "        if not os.path.exists(full_path):\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                with open(full_path, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "\n",
    "\n",
    "def rename_files(config_path, save_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        rename_config = config.get('rename')\n",
    "\n",
    "    for old_name, new_name in rename_config.items():\n",
    "        old_file_path = os.path.join(save_path, old_name)\n",
    "        new_file_path = os.path.join(save_path, new_name)\n",
    "\n",
    "        if os.path.exists(old_file_path):\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "            print(f\"Fichier renommé : {old_name} -> {new_name}\")\n",
    "        else:\n",
    "            print(f\"Fichier non trouvé : {old_name}\")\n",
    "\n",
    "def download_and_process_datasets(base_url='https://www.data.gouv.fr/api/1/datasets/53698f4ca3a729239d2036df/',\n",
    "                                  config_path='../config.yml',\n",
    "                                  save_path='../raw_data/'):\n",
    "    datasets = get_datasets_url(base_url)\n",
    "    categories = [\"lieux\", \"usagers\", \"car\", \"vehicule\"]\n",
    "\n",
    "    categorized_urls = {category: {i: j for i, j in datasets.items() if i.startswith(category)}\n",
    "                        for category in categories}\n",
    "\n",
    "    for category, url_dict in categorized_urls.items():\n",
    "        download_and_save_datasets(url_dict, save_path)\n",
    "\n",
    "    rename_files(config_path, save_path)\n",
    "\n",
    "    return categorized_urls\n",
    "\n",
    "\n",
    "def concat_files(starting_word):\n",
    "\n",
    "    chemin_fichier_yml = '../config.yml'\n",
    "    with open(chemin_fichier_yml, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "        config_sep = config.get('sep')\n",
    "        config_encoding = config.get('encoding')\n",
    "\n",
    "    chemin_dossier = '../raw_data/'\n",
    "\n",
    "    df_concat = pd.DataFrame()\n",
    "    files = [file for file in os.listdir(chemin_dossier) if file.endswith('.csv') and file.startswith(starting_word)]\n",
    "\n",
    "    print(files)\n",
    "    for file in files:\n",
    "        chemin_fichier = os.path.join(chemin_dossier, file)\n",
    "\n",
    "        if file in config_sep:\n",
    "            sep = config_sep[file]\n",
    "        else:\n",
    "            sep = ','\n",
    "\n",
    "        if file in config_encoding:\n",
    "            encoding = config_encoding[file]\n",
    "        else:\n",
    "            encoding = 'utf-8'\n",
    "\n",
    "        df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n",
    "\n",
    "        df_concat = pd.concat([df_concat, df1])\n",
    "\n",
    "    return df_concat\n",
    "\n",
    "download_and_process_datasets()\n",
    "\n",
    "carac_df = concat_files(\"caracteristiques\")\n",
    "lieux_df = concat_files(\"lieux\")\n",
    "usager_df = concat_files(\"usagers\")\n",
    "vehi_df = concat_files(\"vehicules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "usager_df['grav'] = usager_df['grav'].replace({-1: 1})\n",
    "usager_df['grav'].fillna(1, inplace=True)\n",
    "\n",
    "usager_df['sexe'] = usager_df['sexe'].replace({-1: 1})\n",
    "usager_df['sexe'].fillna(1, inplace=True)\n",
    "# on remplace les valeurs nulles par la plus fréquentes\n",
    "\n",
    "# Supposons que votre DataFrame s'appelle usager_df et la colonne en question 'trajet'\n",
    "colonne_a_imputer = usager_df['trajet'].fillna(5)\n",
    "\n",
    "# Obtenir la distribution des valeurs existantes sans tenir compte de 0 et -1\n",
    "distribution = colonne_a_imputer[~colonne_a_imputer.isin([0, -1])].value_counts(normalize=True)\n",
    "\n",
    "# Remplacer les valeurs manquantes par échantillonnage de la distribution\n",
    "valeurs_manquantes = (colonne_a_imputer.isin([0, -1]))\n",
    "colonne_a_imputer[valeurs_manquantes] = np.random.choice(distribution.index, size=valeurs_manquantes.sum(), p=distribution.values)\n",
    "\n",
    "# Assurez-vous que la colonne est de type entier (si nécessaire)\n",
    "usager_df['trajet'] = colonne_a_imputer.astype(int)\n",
    "\n",
    "# Remplacez les valeurs -1 par 1 (comme indiqué dans votre code d'origine)\n",
    "usager_df['trajet'] = usager_df['trajet'].replace({-1: 1})\n",
    "\n",
    "# usager_df['secu'].fillna(usager_df['secu1'])\n",
    "# #on rempalce les valeurs nulles par les valeurs nulles de secu (avant 2019) par les valeurs de secu1(après 2019)\n",
    "# usager_df['secu'] = usager_df['secu'].where(usager_df['secu'] <= 0, 1)\n",
    "# # on normalise les valeurs secu\n",
    "\n",
    "# # Remplacer les valeurs -1 par 0 dans 'locp'\n",
    "# usager_df['locp'] = usager_df['locp'].replace({-1: 0})\n",
    "\n",
    "# # Remplacer les valeurs manquantes dans 'locp' par 0\n",
    "# usager_df['locp'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# usager_df['actp'].value_counts()\n",
    "# usager_df['actp'].fillna(0, inplace=True)\n",
    "# usager_df['actp'] = pd.to_numeric(usager_df['actp'], errors='coerce').fillna(0).astype(int)\n",
    "# usager_df['actp'].astype(float).astype(int)\n",
    "# usager_df['actp'] = usager_df['actp'].replace({-1:0})\n",
    "# # on normalise les valeurs actp\n",
    "\n",
    "# usager_df['etatp'].value_counts()\n",
    "# usager_df['etatp'] = usager_df['etatp'].replace({-1:0})\n",
    "# usager_df['etatp'].fillna(0, inplace=True)\n",
    "# # onconcat les valeurs manquantes\n",
    "\n",
    "# # Supposons que votre DataFrame s'appelle usager_df\n",
    "# # Drop les lignes avec des valeurs manquantes dans 'an_nais'\n",
    "# usager_df.dropna(subset=['an_nais'], inplace=True)\n",
    "\n",
    "# # Remplacer les valeurs 0 dans 'an_nais' par la moyenne\n",
    "# moyenne_an_nais = usager_df['an_nais'].mean()\n",
    "# usager_df['an_nais'] = usager_df['an_nais'].replace({0: moyenne_an_nais})\n",
    "\n",
    "\n",
    "# usager_df_clean = usager_df.drop(columns=['place','catu', 'secu1','secu2','secu3', 'num_veh','id_vehicule','id_usager'])\n",
    "# # on drop les colonnes non pertinentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    1362349\n",
       "1     480089\n",
       "4     355726\n",
       "9     263044\n",
       "3      98860\n",
       "2      76309\n",
       "Name: trajet, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usager_df.trajet.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    1361651\n",
       "1     480237\n",
       "4     355937\n",
       "9     263487\n",
       "3      98873\n",
       "2      76192\n",
       "Name: trajet, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_trajet(usager_df).trajet.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming usager_df is your initial DataFrame\n",
    "processed_usager_df = (usager_df\n",
    "                .pipe(process_grav_sexe, column='grav')\n",
    "                .pipe(process_grav_sexe, column='sexe')\n",
    "                .pipe(process_trajet)\n",
    "                .pipe(process_secu)\n",
    "                .pipe(process_actp)\n",
    "                .pipe(process_locp_etatp, columns=['locp', 'etatp'])\n",
    "                .pipe(process_an_nais)\n",
    "                .pipe(drop_irrelevant_columns, columns=['place', 'catu', 'secu1', 'secu2', 'secu3', 'num_veh', 'id_vehicule', 'id_usager']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    2241993\n",
       "-1     185666\n",
       " 3     159399\n",
       " 9      14751\n",
       " 1      12228\n",
       " 5      11933\n",
       " 2       6014\n",
       " 4       3767\n",
       " 6        514\n",
       " 7         60\n",
       " 8         52\n",
       "Name: actp, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1913376\n",
       "0       270499\n",
       " -1     185666\n",
       "3       131491\n",
       "3        27908\n",
       "9        12219\n",
       "5        10401\n",
       "1         9751\n",
       "2         4851\n",
       "4         3236\n",
       "9         2532\n",
       "1         2477\n",
       "5         1532\n",
       "B         1234\n",
       "2         1163\n",
       "4          531\n",
       "A          422\n",
       "6          408\n",
       "6          106\n",
       "7           60\n",
       "8           52\n",
       "Name: actp, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usager_df[['locp', 'actp', 'etatp']][\"actp\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'B'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhandle_locp_actp_etatp\u001b[49m\u001b[43m(\u001b[49m\u001b[43musager_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43metatp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [10], line 17\u001b[0m, in \u001b[0;36mhandle_locp_actp_etatp\u001b[0;34m(df, columns)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_locp_actp_etatp\u001b[39m(df, columns):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[0;32m---> 17\u001b[0m         df[column] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/generic.py:5912\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5905\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   5906\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   5907\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m   5908\u001b[0m     ]\n\u001b[1;32m   5910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5911\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 5912\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5915\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/internals/managers.py:419\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, dtype, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/internals/managers.py:304\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/internals/blocks.py:580\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    578\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 580\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    583\u001b[0m newb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:1292\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1292\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:1237\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1237\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:1154\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   1151\u001b[0m \n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# work around NumPy brokenness, #1987\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(dtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39minteger):\n\u001b[0;32m-> 1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype_intsafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;66;03m# then coerce to a proper dtype and recall astype_nansafe\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m is_datetime64_dtype(dtype):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/_libs/lib.pyx:668\u001b[0m, in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'B'"
     ]
    }
   ],
   "source": [
    "handle_locp_actp_etatp(usager_df, ['locp', 'actp', 'etatp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usager_df.trajet.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Acc</th>\n",
       "      <th>grav</th>\n",
       "      <th>sexe</th>\n",
       "      <th>trajet</th>\n",
       "      <th>secu</th>\n",
       "      <th>locp</th>\n",
       "      <th>actp</th>\n",
       "      <th>etatp</th>\n",
       "      <th>an_nais</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200600000001</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200600000001</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200600000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200600000002</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1972.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200600000002</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138623</th>\n",
       "      <td>201200062248</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138624</th>\n",
       "      <td>201200062249</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138625</th>\n",
       "      <td>201200062249</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1957.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138626</th>\n",
       "      <td>201200062249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1991.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138627</th>\n",
       "      <td>201200062250</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2628018 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Num_Acc  grav  sexe  trajet  secu  locp  actp  etatp  an_nais\n",
       "0       200600000001     4     1       5   1.0   0.0     0    0.0   1949.0\n",
       "1       200600000001     4     2       5   1.0   0.0     0    0.0   1948.0\n",
       "2       200600000001     1     2       5   1.0   0.0     0    0.0   1921.0\n",
       "3       200600000002     4     2       1   1.0   0.0     0    0.0   1972.0\n",
       "4       200600000002     4     2       2   1.0   0.0     0    0.0   1984.0\n",
       "...              ...   ...   ...     ...   ...   ...   ...    ...      ...\n",
       "138623  201200062248     4     1       5   1.0   0.0     0    0.0   1994.0\n",
       "138624  201200062249     3     1       9   1.0   0.0     0    0.0   1987.0\n",
       "138625  201200062249     3     1       5   1.0   0.0     0    0.0   1957.0\n",
       "138626  201200062249     1     1       9   1.0   0.0     0    0.0   1991.0\n",
       "138627  201200062250     4     2       9   1.0   0.0     0    0.0   1984.0\n",
       "\n",
       "[2628018 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usager_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Acc</th>\n",
       "      <th>grav</th>\n",
       "      <th>sexe</th>\n",
       "      <th>trajet</th>\n",
       "      <th>secu</th>\n",
       "      <th>locp</th>\n",
       "      <th>actp</th>\n",
       "      <th>etatp</th>\n",
       "      <th>an_nais</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200600000001</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200600000001</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200600000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200600000002</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1972.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200600000002</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138623</th>\n",
       "      <td>201200062248</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138624</th>\n",
       "      <td>201200062249</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138625</th>\n",
       "      <td>201200062249</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1957.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138626</th>\n",
       "      <td>201200062249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1991.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138627</th>\n",
       "      <td>201200062250</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2628018 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Num_Acc  grav  sexe  trajet  secu  locp  actp  etatp  an_nais\n",
       "0       200600000001     4     1       5   1.0     0     0      0   1949.0\n",
       "1       200600000001     4     2       1   1.0     0     0      0   1948.0\n",
       "2       200600000001     1     2       5   1.0     0     0      0   1921.0\n",
       "3       200600000002     4     2       1   1.0     0     0      0   1972.0\n",
       "4       200600000002     4     2       2   1.0     0     0      0   1984.0\n",
       "...              ...   ...   ...     ...   ...   ...   ...    ...      ...\n",
       "138623  201200062248     4     1       5   1.0     0     0      0   1994.0\n",
       "138624  201200062249     3     1       9   1.0     0     0      0   1987.0\n",
       "138625  201200062249     3     1       5   1.0     0     0      0   1957.0\n",
       "138626  201200062249     1     1       9   1.0     0     0      0   1991.0\n",
       "138627  201200062250     4     2       9   1.0     0     0      0   1984.0\n",
       "\n",
       "[2628018 rows x 9 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_usager_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m usager_df \u001b[38;5;241m=\u001b[39m clean_column(usager_df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msexe\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m1\u001b[39m}, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m usager_df \u001b[38;5;241m=\u001b[39m impute_from_distribution(usager_df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrajet\u001b[39m\u001b[38;5;124m'\u001b[39m, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 18\u001b[0m usager_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrajet\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43musager_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrajet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Handling 'secu' column\u001b[39;00m\n\u001b[1;32m     21\u001b[0m usager_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msecu\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(usager_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msecu1\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/generic.py:5912\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5905\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   5906\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   5907\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m   5908\u001b[0m     ]\n\u001b[1;32m   5910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5911\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 5912\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5915\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/internals/managers.py:419\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, dtype, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/internals/managers.py:304\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/internals/blocks.py:580\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    578\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 580\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    583\u001b[0m newb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:1292\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1292\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:1237\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1237\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:1148\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot astype a timedelta from [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] to [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(arr\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(dtype, np\u001b[38;5;241m.\u001b[39minteger):\n\u001b[0;32m-> 1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mastype_float_to_int_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   1151\u001b[0m \n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# work around NumPy brokenness, #1987\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(dtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39minteger):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:1193\u001b[0m, in \u001b[0;36mastype_float_to_int_nansafe\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;124;03mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(values)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m-> 1193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[1;32m   1194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1195\u001b[0m     )\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "def clean_column(df, column, replace_dict, fill_value, to_numeric=False):\n",
    "    if to_numeric:\n",
    "        df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    df[column] = df[column].replace(replace_dict)\n",
    "    df[column].fillna(fill_value, inplace=True)\n",
    "    return df\n",
    "\n",
    "def impute_from_distribution(df, column, invalid_values):\n",
    "    distribution = df[column][~df[column].isin(invalid_values)].value_counts(normalize=True)\n",
    "    missing_values = df[column].isin(invalid_values)\n",
    "    df.loc[missing_values, column] = np.random.choice(distribution.index, size=missing_values.sum(), p=distribution.values)\n",
    "    return df\n",
    "\n",
    "\n",
    "usager_df = clean_column(usager_df, 'grav', {-1: 1}, 1)\n",
    "usager_df = clean_column(usager_df, 'sexe', {-1: 1}, 1)\n",
    "usager_df = impute_from_distribution(usager_df, 'trajet', [0, -1])\n",
    "usager_df['trajet'] = usager_df['trajet'].astype(int)\n",
    "\n",
    "# Handling 'secu' column\n",
    "usager_df['secu'].fillna(usager_df['secu1'], inplace=True)\n",
    "usager_df = clean_column(usager_df, 'secu', {value: 1 for value in usager_df['secu'] if value > 0}, 1)\n",
    "\n",
    "usager_df = clean_column(usager_df, 'locp', {-1: 0}, 0)\n",
    "usager_df = clean_column(usager_df, 'actp', {-1: 0}, 0, to_numeric=True)\n",
    "usager_df = clean_column(usager_df, 'etatp', {-1: 0}, 0)\n",
    "\n",
    "# Handling 'an_nais' column\n",
    "usager_df.dropna(subset=['an_nais'], inplace=True)\n",
    "average_an_nais = usager_df['an_nais'].mean()\n",
    "usager_df['an_nais'] = usager_df['an_nais'].replace({0: average_an_nais})\n",
    "\n",
    "# Dropping unnecessary columns\n",
    "usager_df_clean = usager_df.drop(columns=['place', 'catu', 'secu1', 'secu2', 'secu3', 'num_veh', 'id_vehicule', 'id_usager'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Acc</th>\n",
       "      <th>grav</th>\n",
       "      <th>sexe</th>\n",
       "      <th>trajet</th>\n",
       "      <th>secu</th>\n",
       "      <th>locp</th>\n",
       "      <th>actp</th>\n",
       "      <th>etatp</th>\n",
       "      <th>an_nais</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200600000001</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1949.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200600000001</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200600000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200600000002</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1972.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200600000002</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138623</th>\n",
       "      <td>201200062248</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138624</th>\n",
       "      <td>201200062249</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138625</th>\n",
       "      <td>201200062249</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1957.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138626</th>\n",
       "      <td>201200062249</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1991.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138627</th>\n",
       "      <td>201200062250</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2628018 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Num_Acc  grav  sexe  trajet  secu  locp  actp  etatp  an_nais\n",
       "0       200600000001     4     1       5   1.0   0.0     0    0.0   1949.0\n",
       "1       200600000001     4     2       5   1.0   0.0     0    0.0   1948.0\n",
       "2       200600000001     1     2       5   1.0   0.0     0    0.0   1921.0\n",
       "3       200600000002     4     2       1   1.0   0.0     0    0.0   1972.0\n",
       "4       200600000002     4     2       2   1.0   0.0     0    0.0   1984.0\n",
       "...              ...   ...   ...     ...   ...   ...   ...    ...      ...\n",
       "138623  201200062248     4     1       5   1.0   0.0     0    0.0   1994.0\n",
       "138624  201200062249     3     1       9   1.0   0.0     0    0.0   1987.0\n",
       "138625  201200062249     3     1       5   1.0   0.0     0    0.0   1957.0\n",
       "138626  201200062249     1     1       9   1.0   0.0     0    0.0   1991.0\n",
       "138627  201200062250     4     2       9   1.0   0.0     0    0.0   1984.0\n",
       "\n",
       "[2628018 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usager_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier renommé : caracteristiques-2017.csv -> caracteristiques_2017.csv\n",
      "Fichier renommé : caracteristiques-2018.csv -> caracteristiques_2018.csv\n",
      "Fichier renommé : caracteristiques-2019.csv -> caracteristiques_2019.csv\n",
      "Fichier renommé : caracteristiques-2020.csv -> caracteristiques_2020.csv\n",
      "Fichier renommé : carcteristiques-2021.csv -> caracteristiques_2021.csv\n",
      "Fichier renommé : carcteristiques-2022.csv -> caracteristiques_2022.csv\n",
      "Fichier renommé : lieux-2017.csv -> lieux_2017.csv\n",
      "Fichier renommé : lieux-2018.csv -> lieux_2018.csv\n",
      "Fichier renommé : lieux-2019.csv -> lieux_2019.csv\n",
      "Fichier renommé : lieux-2020.csv -> lieux_2020.csv\n",
      "Fichier renommé : lieux-2021.csv -> lieux_2021.csv\n",
      "Fichier renommé : lieux-2022.csv -> lieux_2022.csv\n",
      "Fichier renommé : usagers-2017.csv -> usagers_2017.csv\n",
      "Fichier renommé : usagers-2018.csv -> usagers_2018.csv\n",
      "Fichier renommé : usagers-2019.csv -> usagers_2019.csv\n",
      "Fichier renommé : usagers-2020.csv -> usagers_2020.csv\n",
      "Fichier renommé : usagers-2021.csv -> usagers_2021.csv\n",
      "Fichier renommé : usagers-2022.csv -> usagers_2022.csv\n",
      "Fichier renommé : vehicules-2017.csv -> vehicules_2017.csv\n",
      "Fichier renommé : vehicules-2018.csv -> vehicules_2018.csv\n",
      "Fichier renommé : vehicules-2019.csv -> vehicules_2019.csv\n",
      "Fichier renommé : vehicules-2020.csv -> vehicules_2020.csv\n",
      "Fichier renommé : vehicules-2021.csv -> vehicules_2021.csv\n",
      "Fichier renommé : vehicules-2022.csv -> vehicules_2022.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lieux': {'lieux-2022.csv': 'https://www.data.gouv.fr/fr/datasets/r/a6ef711a-1f03-44cb-921a-0ce8ec975995',\n",
       "  'lieux-2021.csv': 'https://www.data.gouv.fr/fr/datasets/r/8a4935aa-38cd-43af-bf10-0209d6d17434',\n",
       "  'lieux-2020.csv': 'https://www.data.gouv.fr/fr/datasets/r/e85c41f7-d4ea-4faf-877f-ab69a620ce21',\n",
       "  'lieux-2019.csv': 'https://www.data.gouv.fr/fr/datasets/r/2ad65965-36a1-4452-9c08-61a6c874e3e6',\n",
       "  'lieux-2018.csv': 'https://www.data.gouv.fr/fr/datasets/r/d9d65ca1-16a3-4ea3-b7c8-2412c92b69d9',\n",
       "  'lieux-2017.csv': 'https://www.data.gouv.fr/fr/datasets/r/9b76a7b6-3eef-4864-b2da-1834417e305c',\n",
       "  'lieux_2016.csv': 'https://www.data.gouv.fr/fr/datasets/r/08b77510-39c4-4761-bf02-19457264790f',\n",
       "  'lieux_2015.csv': 'https://www.data.gouv.fr/fr/datasets/r/31db21ef-4328-4c5e-bf3d-66a8fe82e6a2',\n",
       "  'lieux_2014.csv': 'https://www.data.gouv.fr/fr/datasets/r/617af155-1b7c-41d6-9504-576878c4d9af',\n",
       "  'lieux_2013.csv': 'https://www.data.gouv.fr/fr/datasets/r/1e00e4dd-e204-4a08-9e10-9b8a02791ba9',\n",
       "  'lieux_2012.csv': 'https://www.data.gouv.fr/fr/datasets/r/59cc1244-2397-430a-8afb-6a0a071ff4d2',\n",
       "  'lieux_2011.csv': 'https://www.data.gouv.fr/fr/datasets/r/26d37f6b-3603-42b0-a779-bbeaa19af4a6',\n",
       "  'lieux_2010.csv': 'https://www.data.gouv.fr/fr/datasets/r/86577e9c-56ab-4673-95cb-3351e804fc03',\n",
       "  'lieux_2009.csv': 'https://www.data.gouv.fr/fr/datasets/r/0a25081b-89b6-4f7c-9d31-72ec679f0abf',\n",
       "  'lieux_2008.csv': 'https://www.data.gouv.fr/fr/datasets/r/237a4d23-1b66-43fb-8832-2f89fbbc6beb',\n",
       "  'lieux_2007.csv': 'https://www.data.gouv.fr/fr/datasets/r/1d967969-c3d2-45c6-adc7-b3b72a8c6e89',\n",
       "  'lieux_2006.csv': 'https://www.data.gouv.fr/fr/datasets/r/28b1fbdc-f984-40d8-8614-236ee26adc7c',\n",
       "  'lieux_2005.csv': 'https://www.data.gouv.fr/fr/datasets/r/3a3488e0-86a1-4917-b082-f3bdc25f6922'},\n",
       " 'usagers': {'usagers-2022.csv': 'https://www.data.gouv.fr/fr/datasets/r/62c20524-d442-46f5-bfd8-982c59763ec8',\n",
       "  'usagers-2021.csv': 'https://www.data.gouv.fr/fr/datasets/r/ba5a1956-7e82-41b7-a602-89d7dd484d7a',\n",
       "  'usagers-2020.csv': 'https://www.data.gouv.fr/fr/datasets/r/78c45763-d170-4d51-a881-e3147802d7ee',\n",
       "  'usagers-2019.csv': 'https://www.data.gouv.fr/fr/datasets/r/36b1b7b3-84b4-4901-9163-59ae8a9e3028',\n",
       "  'usagers-2018.csv': 'https://www.data.gouv.fr/fr/datasets/r/72b251e1-d5e1-4c46-a1c2-c65f1b26549a',\n",
       "  'usagers-2017.csv': 'https://www.data.gouv.fr/fr/datasets/r/07bfe612-0ad9-48ef-92d3-f5466f8465fe',\n",
       "  'usagers_2016.csv': 'https://www.data.gouv.fr/fr/datasets/r/e4c6f4fe-7c68-4a1d-9bb6-b0f1f5d45526',\n",
       "  'usagers_2015.csv': 'https://www.data.gouv.fr/fr/datasets/r/b43a4237-9359-4217-b833-8d3dc29a6c24',\n",
       "  'usagers_2014.csv': 'https://www.data.gouv.fr/fr/datasets/r/457c10ff-ea6c-4238-9af1-d8dc62b896d4',\n",
       "  'usagers_2013.csv': 'https://www.data.gouv.fr/fr/datasets/r/af4349c5-0293-4639-8694-b8b628bfc6c3',\n",
       "  'usagers_2012.csv': 'https://www.data.gouv.fr/fr/datasets/r/a19e060e-1c18-4272-ac4e-d4745ab8fade',\n",
       "  'usagers_2011.csv': 'https://www.data.gouv.fr/fr/datasets/r/bd946492-31b3-428e-8494-a1e203bdc9cc',\n",
       "  'usagers_2010.csv': 'https://www.data.gouv.fr/fr/datasets/r/c5e5664d-1483-41da-a4c6-5f1727d7a353',\n",
       "  'usagers_2009.csv': 'https://www.data.gouv.fr/fr/datasets/r/2387db3d-11ee-4df4-aa31-4c3c748244d4',\n",
       "  'usagers_2008.csv': 'https://www.data.gouv.fr/fr/datasets/r/433e26cf-d4c8-4dd9-b3f2-ecbc8a8f0509',\n",
       "  'usagers_2007.csv': 'https://www.data.gouv.fr/fr/datasets/r/c5c30fc2-9bfd-4bcd-b45b-f01a31f1d087',\n",
       "  'usagers_2006.csv': 'https://www.data.gouv.fr/fr/datasets/r/ebb4c37e-1616-497d-b5ed-f8113bed2ae7',\n",
       "  'usagers_2005.csv': 'https://www.data.gouv.fr/fr/datasets/r/cecdbd46-11f2-41fa-b0bd-e6e223de6b3c'},\n",
       " 'car': {'carcteristiques-2022.csv': 'https://www.data.gouv.fr/fr/datasets/r/5fc299c0-4598-4c29-b74c-6a67b0cc27e7',\n",
       "  'carcteristiques-2021.csv': 'https://www.data.gouv.fr/fr/datasets/r/85cfdc0c-23e4-4674-9bcd-79a970d7269b',\n",
       "  'caracteristiques-2020.csv': 'https://www.data.gouv.fr/fr/datasets/r/07a88205-83c1-4123-a993-cba5331e8ae0',\n",
       "  'caracteristiques-2019.csv': 'https://www.data.gouv.fr/fr/datasets/r/e22ba475-45a3-46ac-a0f7-9ca9ed1e283a',\n",
       "  'caracteristiques-2018.csv': 'https://www.data.gouv.fr/fr/datasets/r/6eee0852-cbd7-447e-bd70-37c433029405',\n",
       "  'caracteristiques-2017.csv': 'https://www.data.gouv.fr/fr/datasets/r/9a7d408b-dd72-4959-ae7d-c854ec505354',\n",
       "  'caracteristiques_2016.csv': 'https://www.data.gouv.fr/fr/datasets/r/96aadc9f-0b55-4e9a-a70e-c627ed97e6f7',\n",
       "  'caracteristiques_2015.csv': 'https://www.data.gouv.fr/fr/datasets/r/185fbdc7-d4c5-4522-888e-ac9550718f71',\n",
       "  'caracteristiques_2014.csv': 'https://www.data.gouv.fr/fr/datasets/r/85dfe8c6-589f-4e76-8a07-9f59e49ec10d',\n",
       "  'caracteristiques_2013.csv': 'https://www.data.gouv.fr/fr/datasets/r/18b1a57a-57bf-4bf1-b9ee-dfa5a3154225',\n",
       "  'caracteristiques_2012.csv': 'https://www.data.gouv.fr/fr/datasets/r/b2518ec1-6529-47bc-9d55-40e2effeb0e7',\n",
       "  'caracteristiques_2011.csv': 'https://www.data.gouv.fr/fr/datasets/r/37991267-8a15-4a9d-9b1c-ff3e6bea3625',\n",
       "  'caracteristiques_2010.csv': 'https://www.data.gouv.fr/fr/datasets/r/decdfe8c-38ff-4a06-b7fc-615785f2914d',\n",
       "  'caracteristiques_2009.csv': 'https://www.data.gouv.fr/fr/datasets/r/fdfacdb9-f48e-4759-bae5-48d063216acb',\n",
       "  'caracteristiques_2008.csv': 'https://www.data.gouv.fr/fr/datasets/r/722ebb99-c8b2-4635-bf8d-125dd280ee42',\n",
       "  'caracteristiques_2007.csv': 'https://www.data.gouv.fr/fr/datasets/r/6fc7b169-4dfe-442c-8c28-8bd773aeddf8',\n",
       "  'caracteristiques_2006.csv': 'https://www.data.gouv.fr/fr/datasets/r/fafa33cf-50cb-4092-a819-d5209f684089',\n",
       "  'caracteristiques_2005.csv': 'https://www.data.gouv.fr/fr/datasets/r/a47866f7-ece1-4de8-8d31-3a1b4f477e08'},\n",
       " 'vehicule': {'vehicules-2022.csv': 'https://www.data.gouv.fr/fr/datasets/r/c9742921-4427-41e5-81bc-f13af8bc31a0',\n",
       "  'vehicules-2021.csv': 'https://www.data.gouv.fr/fr/datasets/r/0bb5953a-25d8-46f8-8c25-b5c2f5ba905e',\n",
       "  'vehicules-2020.csv': 'https://www.data.gouv.fr/fr/datasets/r/a66be22f-c346-49af-b196-71df24702250',\n",
       "  'vehicules-2019.csv': 'https://www.data.gouv.fr/fr/datasets/r/780cd335-5048-4bd6-a841-105b44eb2667',\n",
       "  'vehicules-2018.csv': 'https://www.data.gouv.fr/fr/datasets/r/b4aaeede-1a80-4d76-8f97-543dad479167',\n",
       "  'vehicules-2017.csv': 'https://www.data.gouv.fr/fr/datasets/r/d6103d0c-6db5-466f-b724-91cbea521533',\n",
       "  'vehicules_2016.csv': 'https://www.data.gouv.fr/fr/datasets/r/be2191a6-a7cd-446f-a9fc-8d698688eb9e',\n",
       "  'vehicules_2015.csv': 'https://www.data.gouv.fr/fr/datasets/r/3420157e-7d23-4832-a710-a3a2f2df909c',\n",
       "  'vehicules_2014.csv': 'https://www.data.gouv.fr/fr/datasets/r/86c64436-427f-4042-a4ee-ed0aa31bac76',\n",
       "  'vehicules_2013.csv': 'https://www.data.gouv.fr/fr/datasets/r/3c059a3c-4624-4513-b3a4-2b18c48dfd47',\n",
       "  'vehicules_2012.csv': 'https://www.data.gouv.fr/fr/datasets/r/48683290-0d4d-429a-8fb6-977887098d5d',\n",
       "  'vehicules_2011.csv': 'https://www.data.gouv.fr/fr/datasets/r/569e3f44-ff4c-4a25-bb45-f4a3646b392d',\n",
       "  'vehicules_2010.csv': 'https://www.data.gouv.fr/fr/datasets/r/4dd8a9ea-785f-4e3f-8f83-3838a60ac7f5',\n",
       "  'vehicules_2009.csv': 'https://www.data.gouv.fr/fr/datasets/r/787ba26e-2588-47aa-b73d-346f120f9c59',\n",
       "  'vehicules_2008.csv': 'https://www.data.gouv.fr/fr/datasets/r/6d9e4024-8207-4020-ae4c-5b83504e7268',\n",
       "  'vehicules_2007.csv': 'https://www.data.gouv.fr/fr/datasets/r/6e905a7a-c48d-4f5c-a0bb-54b83c8dfe5f',\n",
       "  'vehicules_2006.csv': 'https://www.data.gouv.fr/fr/datasets/r/c3362179-9c39-4056-9503-ce00ea6b810e',\n",
       "  'vehicules_2005.csv': 'https://www.data.gouv.fr/fr/datasets/r/924b962b-4400-4468-9f7d-0bdba28f51e9'}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# import requests\n",
    "# import yaml\n",
    "\n",
    "# def download_and_process_datasets(base_url='https://www.data.gouv.fr/api/1/datasets/53698f4ca3a729239d2036df/',\n",
    "#                                   config_path='../config.yml',\n",
    "#                                   save_path='../raw_data/'):\n",
    "#     # Function to get datasets URL\n",
    "#     def get_datasets_url(url=base_url):\n",
    "#         r = requests.get(url).json()\n",
    "#         return {el['title']: el['latest'] for el in r['resources'] if el['title'].endswith(\".csv\") and not el['title'].startswith(\"vehicules-immatricules\") }\n",
    "\n",
    "#     # Categorizing datasets\n",
    "#     datasets = get_datasets_url()\n",
    "#     categories = {\n",
    "#         \"lieux\": \"lieux\",\n",
    "#         \"usagers\": \"usagers\",\n",
    "#         \"car\": \"car\",\n",
    "#         \"vehicule\": \"vehicule\"\n",
    "#     }\n",
    "\n",
    "#     categorized_urls = {category: {i: j for i, j in datasets.items() if i.startswith(prefix)}\n",
    "#                             for category, prefix in categories.items()}\n",
    "\n",
    "#     # Downloading and saving datasets\n",
    "#     for category, url_dict in categorized_urls.items():\n",
    "#         for path, url in url_dict.items():\n",
    "#             full_path = os.path.join(save_path, path)\n",
    "#             if not os.path.exists(full_path):\n",
    "#                 response = requests.get(url)\n",
    "#                 if response.status_code == 200:\n",
    "#                     with open(full_path, 'wb') as f:\n",
    "#                         f.write(response.content)\n",
    "\n",
    "#     # Loading configuration for renaming\n",
    "#     with open(config_path, 'r') as f:\n",
    "#         config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "#         rename_config = config.get('rename')\n",
    "\n",
    "#     # Renaming files\n",
    "#     for old_name, new_name in rename_config.items():\n",
    "#         old_file_path = os.path.join(save_path, old_name)\n",
    "#         new_file_path = os.path.join(save_path, new_name)\n",
    "\n",
    "#         if os.path.exists(old_file_path):\n",
    "#             os.rename(old_file_path, new_file_path)\n",
    "#             print(f\"Fichier renommé : {old_name} -> {new_name}\")\n",
    "#         else:\n",
    "#             print(f\"Fichier non trouvé : {old_name}\")\n",
    "\n",
    "#     return categorized_urls\n",
    "\n",
    "# def concat_files(starting_word):\n",
    "\n",
    "#     chemin_fichier_yml = '../config.yml'\n",
    "#     with open(chemin_fichier_yml, 'r') as f:\n",
    "#         config = yaml.safe_load(f)\n",
    "#         config_sep = config.get('sep')\n",
    "#         config_encoding = config.get('encoding')\n",
    "\n",
    "#     chemin_dossier = '../raw_data/'\n",
    "\n",
    "#     df_concat = pd.DataFrame()\n",
    "#     files = [file for file in os.listdir(chemin_dossier) if file.endswith('.csv') and file.startswith(starting_word)]\n",
    "\n",
    "#     print(files)\n",
    "#     for file in files:\n",
    "#         chemin_fichier = os.path.join(chemin_dossier, file)\n",
    "\n",
    "#         if file in config_sep:\n",
    "#             sep = config_sep[file]\n",
    "#         else:\n",
    "#             sep = ','\n",
    "\n",
    "#         if file in config_encoding:\n",
    "#             encoding = config_encoding[file]\n",
    "#         else:\n",
    "#             encoding = 'utf-8'\n",
    "\n",
    "#         df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n",
    "\n",
    "#         df_concat = pd.concat([df_concat, df1])\n",
    "\n",
    "#     return df_concat\n",
    "\n",
    "\n",
    "# download_and_process_datasets()\n",
    "\n",
    "# carac_df = concat_files(\"caracteristiques\")\n",
    "# lieux_df = concat_files(\"lieux\")\n",
    "# usager_df = concat_files(\"usagers\")\n",
    "# vehi_df = concat_files(\"vehicules\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "catv_group_named = {\n",
    "    \"Bicycles_ElectricScooters\": [1, 80, 50, 60],  # Bicycles, E-bikes, and Personal Mobility Devices\n",
    "    \"Cars\": [3, 7, 8, 9],  # Cars including light vehicles, VL + caravane, VL + remorque\n",
    "    \"Motorcycles_Scooters\": [2, 30, 31, 32, 33, 34, 41, 42, 43, 4, 5, 6],  # Motorcycles, scooters, scooter immatriculé, motocyclette, side-car\n",
    "    \"HeavyVehicles_Buses\": [10, 13, 14, 15, 16, 17, 37, 38, 18, 19],  # Utility vehicles, heavy trucks, buses, transport en commun, tramway\n",
    "    \"Others_SpecialVehicles\": [0, 20, 21, 39, 40, 99, 11, 12, 35, 36]  # Special vehicles and others, VU + caravane, VU + remorque\n",
    "}\n",
    "\n",
    "\n",
    "obs_group_named = {\n",
    "    \"NoObstacle\": [-1, 0],  # Without obstacle\n",
    "    \"WithObstacle\": list(range(1, 18))  # With obstacle\n",
    "}\n",
    "\n",
    "obsm_group_named = {\n",
    "    \"Pedestrian_Vehicle_Rail\": [1, 2, 4],  # Pedestrian, Vehicle, Rail Vehicle\n",
    "    \"Animals\": [5, 6],  # Animals\n",
    "    \"Others_NotClassified\": [-1, 0, 9]  # Other or Not Classified\n",
    "}\n",
    "\n",
    "choc_group_named = {\n",
    "    \"NoImpact\": [0],  # No impact\n",
    "    \"Impact\": list(range(1, 10))  # Impact\n",
    "}\n",
    "\n",
    "manv_group_named = {\n",
    "    \"BasicManeuvers\": [1, 2, 3],  # Standard driving maneuvers\n",
    "    \"DirectionalChanges\": [11, 12, 13, 14, 15, 16, 17, 18],  # Maneuvers involving directional changes\n",
    "    \"DefensiveManeuvers\": [21, 22],  # Defensive driving maneuvers\n",
    "    \"TrajectoryChanges\": [10],  # Significant trajectory changes\n",
    "    \"RiskyManeuvers\": [4, 5, 6, 7, 8, 9, 19, 26],  # Unusual or risky maneuvers\n",
    "    \"StationaryParkingManeuvers\": [20, 23, 24, 25]  # Stationary or parking related maneuvers\n",
    "}\n",
    "\n",
    "def clean_and_transform_data(df, catv_group_inverted, choc_group_inverted, obs_group_inverted, obsm_group_inverted, manv_group_inverted):\n",
    "    # Drop unnecessary columns\n",
    "    df_modif = df.drop([\"id_vehicule\", \"motor\", \"occutc\", \"senc\"], axis=1)\n",
    "\n",
    "    # CATV: Assign mode to -1 values\n",
    "    df_modif.loc[df_modif.catv == -1, 'catv'] = df_modif.catv.mode()[0]\n",
    "\n",
    "    # Define a function for cleaning and imputing values based on distribution\n",
    "    def clean_and_impute(column):\n",
    "        # Calculate distribution of values greater than or equal to 0\n",
    "        values_distribution = df_modif[column][df_modif[column] >= 0].value_counts(normalize=True)\n",
    "\n",
    "        # Impute NaNs and -1 values\n",
    "        for condition in [df_modif[column].isna(), df_modif[column] == -1]:\n",
    "            new_values = np.random.choice(values_distribution.index, size=condition.sum(), p=values_distribution.values)\n",
    "            df_modif.loc[condition, column] = new_values\n",
    "\n",
    "    # Apply the cleaning and imputing function to specified columns\n",
    "    for col in ['obs', 'obsm', 'choc', 'manv']:\n",
    "        clean_and_impute(col)\n",
    "\n",
    "    # Mapping to group values\n",
    "    df_modif['catv'] = df_modif['catv'].map(catv_group_inverted)\n",
    "    df_modif['choc'] = df_modif['choc'].map(choc_group_inverted)\n",
    "    df_modif['obs'] = df_modif['obs'].map(obs_group_inverted)\n",
    "    df_modif['obsm'] = df_modif['obsm'].map(obsm_group_inverted)\n",
    "    df_modif['manv'] = df_modif['manv'].map(manv_group_inverted)\n",
    "\n",
    "    return df_modif\n",
    "\n",
    "# Example usage\n",
    "cleaned_df = clean_and_transform_data(vehi_df, catv_group_inverted, choc_group_inverted, obs_group_inverted, obsm_group_inverted, manv_group_inverted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requesting API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get datasets DL urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets_url(url='https://www.data.gouv.fr/api/1/datasets/53698f4ca3a729239d2036df/'):\n",
    "    r = requests.get(url).json()\n",
    "    return {el['title']: el['latest'] for el in r['resources'] if el['title'].endswith(\".csv\") and not el['title'].startswith(\"vehicules-immatricules\") }\n",
    "\n",
    "lieux_datasets = {i:j for i,j in get_datasets_url().items() if i.startswith(\"lieux\")}\n",
    "usagers_datasets = {i:j for i,j in get_datasets_url().items() if i.startswith(\"usagers\")}\n",
    "car_datasets = {i:j for i,j in get_datasets_url().items() if i.startswith(\"car\")}\n",
    "vehicule_datasets = {i:j for i,j in get_datasets_url().items() if i.startswith(\"vehicule\")}\n",
    "\n",
    "all_urls = [lieux_datasets, usagers_datasets, car_datasets,vehicule_datasets]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading csv's if not already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lieux_2015.csv',\n",
       " 'usagers_2006.csv',\n",
       " 'caracteristiques_2006.csv',\n",
       " 'caracteristiques_2016.csv',\n",
       " 'caracteristiques_2020.csv',\n",
       " 'caracteristiques_2008.csv',\n",
       " 'usagers-2017.csv',\n",
       " 'vehicules-2021.csv',\n",
       " 'usagers_2021.csv',\n",
       " 'caracteristiques-2017.csv',\n",
       " 'usagers-2020.csv',\n",
       " 'lieux_2010.csv',\n",
       " 'usagers_2020.csv',\n",
       " 'vehicules_2005.csv',\n",
       " 'lieux_2005.csv',\n",
       " 'caracteristiques_2022.csv',\n",
       " 'usagers-2018.csv',\n",
       " 'lieux-2018.csv',\n",
       " 'lieux_2019.csv',\n",
       " 'vehicules-2017.csv',\n",
       " 'lieux_2008.csv',\n",
       " 'caracteristiques_2012.csv',\n",
       " 'vehicules_2018.csv',\n",
       " 'usagers_2014.csv',\n",
       " 'caracteristiques_2007.csv',\n",
       " 'usagers_2010.csv',\n",
       " 'vehicules_2011.csv',\n",
       " 'vehicules-2022.csv',\n",
       " 'usagers_2007.csv',\n",
       " 'vehicules_2013.csv',\n",
       " 'lieux_2011.csv',\n",
       " 'lieux_2006.csv',\n",
       " 'lieux_2017.csv',\n",
       " 'usagers_2005.csv',\n",
       " 'lieux_2018.csv',\n",
       " 'lieux_2014.csv',\n",
       " 'caracteristiques-2020.csv',\n",
       " 'usagers_2018.csv',\n",
       " 'lieux_2022.csv',\n",
       " 'usagers-2019.csv',\n",
       " 'usagers_2019.csv',\n",
       " 'carcteristiques-2022.csv',\n",
       " 'caracteristiques_2011.csv',\n",
       " 'caracteristiques-2019.csv',\n",
       " 'usagers_2016.csv',\n",
       " 'vehicules_2017.csv',\n",
       " 'lieux_2009.csv',\n",
       " 'vehicules_2006.csv',\n",
       " 'caracteristiques-2018.csv',\n",
       " 'vehicules-2019.csv',\n",
       " 'usagers_2017.csv',\n",
       " 'vehicules_2016.csv',\n",
       " 'lieux_2007.csv',\n",
       " 'lieux-2017.csv',\n",
       " 'lieux_2020.csv',\n",
       " 'vehicules_2020.csv',\n",
       " 'usagers_2022.csv',\n",
       " 'vehicules_2008.csv',\n",
       " 'vehicules_2014.csv',\n",
       " 'lieux-2020.csv',\n",
       " 'caracteristiques_2021.csv',\n",
       " 'usagers-2021.csv',\n",
       " 'lieux_2021.csv',\n",
       " 'vehicules_2009.csv',\n",
       " 'usagers_2008.csv',\n",
       " 'lieux-2021.csv',\n",
       " 'vehicules_2022.csv',\n",
       " 'lieux_2013.csv',\n",
       " 'usagers_2009.csv',\n",
       " 'caracteristiques_2013.csv',\n",
       " 'vehicules_2007.csv',\n",
       " 'caracteristiques_2014.csv',\n",
       " 'usagers_2013.csv',\n",
       " 'vehicules_2021.csv',\n",
       " 'vehicules_2019.csv',\n",
       " 'vehicules_2015.csv',\n",
       " 'lieux_2012.csv',\n",
       " 'usagers_2015.csv',\n",
       " 'lieux-2022.csv',\n",
       " 'vehicules_2010.csv',\n",
       " 'lieux_2016.csv',\n",
       " 'caracteristiques_2009.csv',\n",
       " 'lieux-2019.csv',\n",
       " 'caracteristiques_2017.csv',\n",
       " 'carcteristiques-2021.csv',\n",
       " 'vehicules-2018.csv',\n",
       " 'caracteristiques_2019.csv',\n",
       " 'usagers_2011.csv',\n",
       " 'vehicules_2012.csv',\n",
       " 'caracteristiques_2018.csv',\n",
       " 'caracteristiques_2010.csv',\n",
       " 'caracteristiques_2015.csv',\n",
       " 'usagers-2022.csv',\n",
       " 'usagers_2012.csv',\n",
       " 'caracteristiques_2005.csv',\n",
       " 'vehicules-2020.csv']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for url_dict in all_urls:\n",
    "    for path, url in url_dict.items():\n",
    "        path = '../raw_data/' + path\n",
    "        if not os.path.exists(path):\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                with open(path, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "\n",
    "# folder = \"../raw_data/\"\n",
    "# os.listdir(folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect separator & read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detect_separator(file_path):\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         first_line = file.readline()\n",
    "#         if ';' in first_line:\n",
    "#             return ';'\n",
    "#         elif '|' in first_line:\n",
    "#             return '|'\n",
    "#         else:\n",
    "#             return ','\n",
    "\n",
    "# folder = \"../raw_data/\"\n",
    "# dff = []\n",
    "# files = [file for file in os.listdir(folder)]\n",
    "\n",
    "# for file in files:\n",
    "#     file_path = os.path.join(folder, file)\n",
    "#     sep = detect_separator(file_path)\n",
    "#     df = pd.read_csv(file_path, sep=sep)\n",
    "#     dff.append(df)\n",
    "\n",
    "# df_final = pd.concat(dff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### changing file names w/ YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier renommé : caracteristiques-2017.csv -> caracteristiques_2017.csv\n",
      "Fichier renommé : caracteristiques-2018.csv -> caracteristiques_2018.csv\n",
      "Fichier renommé : caracteristiques-2019.csv -> caracteristiques_2019.csv\n",
      "Fichier renommé : caracteristiques-2020.csv -> caracteristiques_2020.csv\n",
      "Fichier renommé : carcteristiques-2021.csv -> caracteristiques_2021.csv\n",
      "Fichier renommé : carcteristiques-2022.csv -> caracteristiques_2022.csv\n",
      "Fichier renommé : lieux-2017.csv -> lieux_2017.csv\n",
      "Fichier renommé : lieux-2018.csv -> lieux_2018.csv\n",
      "Fichier renommé : lieux-2019.csv -> lieux_2019.csv\n",
      "Fichier renommé : lieux-2020.csv -> lieux_2020.csv\n",
      "Fichier renommé : lieux-2021.csv -> lieux_2021.csv\n",
      "Fichier renommé : lieux-2022.csv -> lieux_2022.csv\n",
      "Fichier renommé : usagers-2017.csv -> usagers_2017.csv\n",
      "Fichier renommé : usagers-2018.csv -> usagers_2018.csv\n",
      "Fichier renommé : usagers-2019.csv -> usagers_2019.csv\n",
      "Fichier renommé : usagers-2020.csv -> usagers_2020.csv\n",
      "Fichier renommé : usagers-2021.csv -> usagers_2021.csv\n",
      "Fichier renommé : usagers-2022.csv -> usagers_2022.csv\n",
      "Fichier renommé : vehicules-2017.csv -> vehicules_2017.csv\n",
      "Fichier renommé : vehicules-2018.csv -> vehicules_2018.csv\n",
      "Fichier renommé : vehicules-2019.csv -> vehicules_2019.csv\n",
      "Fichier renommé : vehicules-2020.csv -> vehicules_2020.csv\n",
      "Fichier renommé : vehicules-2021.csv -> vehicules_2021.csv\n",
      "Fichier renommé : vehicules-2022.csv -> vehicules_2022.csv\n"
     ]
    }
   ],
   "source": [
    "chemin_fichier_yml = '../config.yml'\n",
    "chemin_dossier = '../raw_data/'\n",
    "\n",
    "\n",
    "with open (chemin_fichier_yml, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    rename_config = config.get('rename')\n",
    "\n",
    "# change file names\n",
    "for old_name, new_name in rename_config.items():\n",
    "    chemin_ancien_fichier = os.path.join(chemin_dossier, old_name)\n",
    "    chemin_nouveau_fichier = os.path.join(chemin_dossier, new_name)\n",
    "\n",
    "    if os.path.exists(chemin_ancien_fichier):\n",
    "        os.rename(chemin_ancien_fichier, chemin_nouveau_fichier)\n",
    "        print(f\"Fichier renommé : {old_name} -> {new_name}\")\n",
    "    else:\n",
    "        print(f\"Fichier non trouvé : {old_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### changing files encoding w/ YAML + concatenating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['caracteristiques_2006.csv', 'caracteristiques_2016.csv', 'caracteristiques_2020.csv', 'caracteristiques_2008.csv', 'caracteristiques_2022.csv', 'caracteristiques_2012.csv', 'caracteristiques_2007.csv', 'caracteristiques_2011.csv', 'caracteristiques_2021.csv', 'caracteristiques_2013.csv', 'caracteristiques_2014.csv', 'caracteristiques_2009.csv', 'caracteristiques_2017.csv', 'caracteristiques_2019.csv', 'caracteristiques_2018.csv', 'caracteristiques_2010.csv', 'caracteristiques_2015.csv', 'caracteristiques_2005.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35289/3481851178.py:28: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lieux_2015.csv', 'lieux_2010.csv', 'lieux_2005.csv', 'lieux_2019.csv', 'lieux_2008.csv', 'lieux_2011.csv', 'lieux_2006.csv', 'lieux_2017.csv', 'lieux_2018.csv', 'lieux_2014.csv', 'lieux_2022.csv', 'lieux_2009.csv', 'lieux_2007.csv', 'lieux_2020.csv', 'lieux_2021.csv', 'lieux_2013.csv', 'lieux_2012.csv', 'lieux_2016.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35289/3481851178.py:28: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n",
      "/tmp/ipykernel_35289/3481851178.py:28: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n",
      "/tmp/ipykernel_35289/3481851178.py:28: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n",
      "/tmp/ipykernel_35289/3481851178.py:28: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['usagers_2006.csv', 'usagers_2021.csv', 'usagers_2020.csv', 'usagers_2014.csv', 'usagers_2010.csv', 'usagers_2007.csv', 'usagers_2005.csv', 'usagers_2018.csv', 'usagers_2019.csv', 'usagers_2016.csv', 'usagers_2017.csv', 'usagers_2022.csv', 'usagers_2008.csv', 'usagers_2009.csv', 'usagers_2013.csv', 'usagers_2015.csv', 'usagers_2011.csv', 'usagers_2012.csv']\n",
      "['vehicules_2005.csv', 'vehicules_2018.csv', 'vehicules_2011.csv', 'vehicules_2013.csv', 'vehicules_2017.csv', 'vehicules_2006.csv', 'vehicules_2016.csv', 'vehicules_2020.csv', 'vehicules_2008.csv', 'vehicules_2014.csv', 'vehicules_2009.csv', 'vehicules_2022.csv', 'vehicules_2007.csv', 'vehicules_2021.csv', 'vehicules_2019.csv', 'vehicules_2015.csv', 'vehicules_2010.csv', 'vehicules_2012.csv']\n"
     ]
    }
   ],
   "source": [
    "def concat_files(starting_word):\n",
    "\n",
    "    chemin_fichier_yml = '../config.yml'\n",
    "    with open(chemin_fichier_yml, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "        config_sep = config.get('sep')\n",
    "        config_encoding = config.get('encoding')\n",
    "\n",
    "    chemin_dossier = '../raw_data/'\n",
    "\n",
    "    df_concat = pd.DataFrame()\n",
    "    files = [file for file in os.listdir(chemin_dossier) if file.endswith('.csv') and file.startswith(starting_word)]\n",
    "\n",
    "    print(files)\n",
    "    for file in files:\n",
    "        chemin_fichier = os.path.join(chemin_dossier, file)\n",
    "\n",
    "        if file in config_sep:\n",
    "            sep = config_sep[file]\n",
    "        else:\n",
    "            sep = ','\n",
    "\n",
    "        if file in config_encoding:\n",
    "            encoding = config_encoding[file]\n",
    "        else:\n",
    "            encoding = 'utf-8'\n",
    "\n",
    "        df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n",
    "\n",
    "        df_concat = pd.concat([df_concat, df1])\n",
    "\n",
    "    return df_concat\n",
    "\n",
    "carac_df = concat_files(\"caracteristiques\")\n",
    "lieux_df = concat_files(\"lieux\")\n",
    "usager_df = concat_files(\"usagers\")\n",
    "vehi_df = concat_files(\"vehicules\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning vehicule dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless columns\n",
    "vehi_df_modif = vehi_df.drop([\"id_vehicule\", \"motor\", \"occutc\", \"senc\"], axis=1)\n",
    "\n",
    "### REMOVING ACCIDENTS DUPLICATES ###\n",
    "# get bike id's\n",
    "id_bikes = vehi_df_modif[vehi_df_modif.catv == 1].Num_Acc.values\n",
    "\n",
    "# create df of accidents involving bikes (w/ duplicated Num_Acc)\n",
    "bikes_df = vehi_df_modif[vehi_df_modif.Num_Acc.isin(id_bikes)]\n",
    "\n",
    "# get accidents by number of parties involved\n",
    "grouped = bikes_df.groupby('Num_Acc').count()\n",
    "\n",
    "# get ids\n",
    "accident_alone_idx = grouped[grouped.catv == 1].index #12k\n",
    "accident_2p_idx = grouped[grouped.catv == 2].index #71k\n",
    "accident_3p_idx = grouped[grouped.catv > 3].index #263\n",
    "\n",
    "# filter dataset\n",
    "accident_2p = bikes_df[bikes_df.Num_Acc.isin(accident_2p_idx)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "catv_group_named = {\n",
    "    \"Bicycles_ElectricScooters\": [1, 80, 50, 60],  # Bicycles, E-bikes, and Personal Mobility Devices\n",
    "    \"Cars\": [3, 7, 8, 9],  # Cars including light vehicles, VL + caravane, VL + remorque\n",
    "    \"Motorcycles_Scooters\": [2, 30, 31, 32, 33, 34, 41, 42, 43, 4, 5, 6],  # Motorcycles, scooters, scooter immatriculé, motocyclette, side-car\n",
    "    \"HeavyVehicles_Buses\": [10, 13, 14, 15, 16, 17, 37, 38, 18, 19],  # Utility vehicles, heavy trucks, buses, transport en commun, tramway\n",
    "    \"Others_SpecialVehicles\": [0, 20, 21, 39, 40, 99, 11, 12, 35, 36]  # Special vehicles and others, VU + caravane, VU + remorque\n",
    "}\n",
    "\n",
    "\n",
    "obs_group_named = {\n",
    "    \"NoObstacle\": [-1, 0],  # Without obstacle\n",
    "    \"WithObstacle\": list(range(1, 18))  # With obstacle\n",
    "}\n",
    "\n",
    "obsm_group_named = {\n",
    "    \"Pedestrian_Vehicle_Rail\": [1, 2, 4],  # Pedestrian, Vehicle, Rail Vehicle\n",
    "    \"Animals\": [5, 6],  # Animals\n",
    "    \"Others_NotClassified\": [-1, 0, 9]  # Other or Not Classified\n",
    "}\n",
    "\n",
    "choc_group_named = {\n",
    "    \"NoImpact\": [0],  # No impact\n",
    "    \"Impact\": list(range(1, 10))  # Impact\n",
    "}\n",
    "\n",
    "manv_group_named = {\n",
    "    \"BasicManeuvers\": [1, 2, 3],  # Standard driving maneuvers\n",
    "    \"DirectionalChanges\": [11, 12, 13, 14, 15, 16, 17, 18],  # Maneuvers involving directional changes\n",
    "    \"DefensiveManeuvers\": [21, 22],  # Defensive driving maneuvers\n",
    "    \"TrajectoryChanges\": [10],  # Significant trajectory changes\n",
    "    \"RiskyManeuvers\": [4, 5, 6, 7, 8, 9, 19, 26],  # Unusual or risky maneuvers\n",
    "    \"StationaryParkingManeuvers\": [20, 23, 24, 25]  # Stationary or parking related maneuvers\n",
    "}\n",
    "\n",
    "# Inverting the dictionaries for mapping\n",
    "catv_group_inverted = {v: k for k, values in catv_group_named.items() for v in values}\n",
    "obs_group_inverted = {v: k for k, values in obs_group_named.items() for v in values}\n",
    "obsm_group_inverted = {v: k for k, values in obsm_group_named.items() for v in values}\n",
    "choc_group_inverted = {v: k for k, values in choc_group_named.items() for v in values}\n",
    "manv_group_inverted = {v: k for k, values in manv_group_named.items() for v in values}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35289/1814743421.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vehi_df_modif.catv[vehi_df_modif.catv == -1] = vehi_df_modif.catv.mode()[0]\n"
     ]
    }
   ],
   "source": [
    "# drop useless columns\n",
    "vehi_df_modif = vehi_df.drop([\"id_vehicule\", \"motor\", \"occutc\", \"senc\"], axis=1)\n",
    "\n",
    "\n",
    "### CATV ###\n",
    "# assign mode to -1 values in catv\n",
    "vehi_df_modif.catv[vehi_df_modif.catv == -1] = vehi_df_modif.catv.mode()[0]\n",
    "\n",
    "### CLEANING OBS ###\n",
    "# calculate 'obs' values (>0) distribution\n",
    "values_distribution_obs = vehi_df_modif.obs[vehi_df_modif.obs >= 0].value_counts(normalize=True)\n",
    "\n",
    "# impute NaN's w/ 'obs' based on distribution\n",
    "new_values_obs = np.random.choice(values_distribution_obs.index, size=vehi_df_modif['obs'].isna().sum(), p=values_distribution_obs.values)\n",
    "vehi_df_modif.loc[vehi_df_modif['obs'].isna(), 'obs'] = new_values_obs\n",
    "\n",
    "# Repeat for -1 values (not reported)\n",
    "new_values_obs2 = np.random.choice(values_distribution_obs.index, size=(vehi_df_modif['obs'] == -1).sum(), p=values_distribution_obs.values)\n",
    "vehi_df_modif.loc[vehi_df_modif['obs'] == -1, 'obs'] = new_values_obs2\n",
    "\n",
    "# mapping to group 'obs' values\n",
    "\n",
    "\n",
    "### CLEANING OBSM ###\n",
    "# calculate 'obsm' values (>0) distribution\n",
    "values_distribution_obsm = vehi_df_modif.obsm[vehi_df_modif.obsm >= 0].value_counts(normalize=True)\n",
    "\n",
    "# impute NaN's w/ 'obsm' based on distribution\n",
    "new_values_obsm = np.random.choice(values_distribution_obsm.index, size=vehi_df_modif['obsm'].isna().sum(), p=values_distribution_obsm.values)\n",
    "vehi_df_modif.loc[vehi_df_modif['obsm'].isna(), 'obsm'] = new_values_obsm\n",
    "\n",
    "# Repeat for -1 values (not reported)\n",
    "new_values_obsm2 = np.random.choice(values_distribution_obsm.index, size=(vehi_df_modif['obsm'] == -1).sum(), p=values_distribution_obsm.values)\n",
    "vehi_df_modif.loc[vehi_df_modif['obsm'] == -1, 'obsm'] = new_values_obsm2\n",
    "\n",
    "# mapping to group 'obsm' values\n",
    "\n",
    "### CLEANING CHOC ###\n",
    "# Calculate 'choc' values (>0) distribution\n",
    "values_distribution_choc = vehi_df_modif.choc[vehi_df_modif.choc > 0].value_counts(normalize=True)\n",
    "\n",
    "# Impute NaN's in 'choc' based on distribution\n",
    "new_values_choc = np.random.choice(values_distribution_choc.index, size=vehi_df_modif['choc'].isna().sum(), p=values_distribution_choc.values)\n",
    "vehi_df_modif.loc[vehi_df_modif['choc'].isna(), 'choc'] = new_values_choc\n",
    "\n",
    "# Repeat for -1 values (not reported)\n",
    "new_values_choc2 = np.random.choice(values_distribution_choc.index, size=(vehi_df_modif['choc'] == -1).sum(), p=values_distribution_choc.values)\n",
    "vehi_df_modif.loc[vehi_df_modif['choc'] == -1, 'choc'] = new_values_choc2\n",
    "\n",
    "# Repeat for 0 values (no impact)\n",
    "# new_values_choc3 = np.random.choice(values_distribution_choc.index, size=(vehi_df_modif['choc'] == 0).sum(), p=values_distribution_choc.values)\n",
    "# vehi_df_modif.loc[vehi_df_modif['choc'] == 0, 'choc'] = new_values_choc3\n",
    "\n",
    "# mapping to group 'choc' values\n",
    "\n",
    "\n",
    "### CLEANING MANV ###\n",
    "# Calculate 'manv' values (>0) distribution\n",
    "values_distribution_manv = vehi_df_modif.manv[vehi_df_modif.manv > 0].value_counts(normalize=True)\n",
    "\n",
    "# Impute NaN's in 'manv' based on distribution\n",
    "new_values_manv = np.random.choice(values_distribution_manv.index, size=vehi_df_modif['manv'].isna().sum(), p=values_distribution_manv.values)\n",
    "vehi_df_modif.loc[vehi_df_modif['manv'].isna(), 'manv'] = new_values_manv\n",
    "\n",
    "# Repeat for -1 values (not reported)\n",
    "new_values_manv2 = np.random.choice(values_distribution_manv.index, size=(vehi_df_modif['manv'] == -1).sum(), p=values_distribution_manv.values)\n",
    "vehi_df_modif.loc[vehi_df_modif['manv'] == -1, 'manv'] = new_values_manv2\n",
    "\n",
    "# Repeat for 0 values (no maneuver)\n",
    "new_values_manv3 = np.random.choice(values_distribution_manv.index, size=(vehi_df_modif['manv'] == 0).sum(), p=values_distribution_manv.values)\n",
    "vehi_df_modif.loc[vehi_df_modif['manv'] == 0, 'manv'] = new_values_manv3\n",
    "\n",
    "# mapping to group 'choc' values\n",
    "vehi_df_modif['catv'] = vehi_df_modif['catv'].map(catv_group_inverted)\n",
    "vehi_df_modif['choc'] = vehi_df_modif['choc'].map(choc_group_inverted)\n",
    "vehi_df_modif['obs'] = vehi_df_modif['obs'].map(obs_group_inverted)\n",
    "vehi_df_modif['obsm'] = vehi_df_modif['obsm'].map(obsm_group_inverted)\n",
    "vehi_df_modif['manv'] = vehi_df_modif['manv'].map(manv_group_inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehi_df_modif.to_csv('vehicule_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Num_Acc    1176873\n",
       "catv             5\n",
       "obs              2\n",
       "obsm             3\n",
       "choc             2\n",
       "manv             6\n",
       "num_veh        189\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehi_df_modif.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carac_df_modif = carac_df.drop(['gps', 'Accident_Id'], axis=1, inplace=False)\n",
    "\n",
    "\n",
    "\"\"\"Cleaning date's column\"\"\"\n",
    "\n",
    "def process_dates(df):\n",
    "    # Vérifier les dates invalides\n",
    "    invalid_dates = df[(df['jour'] > 31) | ((df['mois'] == 2) & (df['jour'] > 29)) | ((df['mois'].isin([4, 6, 9, 11])) & (df['jour'] > 30))]\n",
    "    df = df.drop(invalid_dates.index)\n",
    "\n",
    "    # Créer la colonne 'date'\n",
    "    df['date'] = pd.to_datetime(df['an'].astype(str).str.zfill(2)\n",
    "                                + df['mois'].astype(str).str.zfill(2)\n",
    "                                + df['jour'].astype(str).str.zfill(2)\n",
    "                                + df['hrmn'].astype(str).str.zfill(4),\n",
    "                                format='%y%m%d%H%M', errors='coerce')\n",
    "\n",
    "    df = df.drop(columns=['an', 'mois', 'jour', 'hrmn'])\n",
    "    return df\n",
    "\n",
    "# Utiliser la fonction sur carac_df_modif\n",
    "carac_df_modif = process_dates(carac_df_modif)\n",
    "\n",
    "\"\"\"Drop Na de Num_Acc\"\"\"\n",
    "\n",
    "carac_df_modif = carac_df_modif.dropna(subset=['Num_Acc'])\n",
    "\n",
    "\n",
    "\"\"\"Clean the column 'lum'\"\"\"\n",
    "\n",
    "values_destribution_lum = carac_df_modif.lum[carac_df_modif['lum'] >= 0].value_counts(normalize=True)\n",
    "new_values_lum = np.random.choice(values_destribution_lum.index, size = (carac_df_modif['lum'] == -1).sum(), p=values_destribution_lum.values)\n",
    "carac_df_modif.loc[carac_df_modif['lum'] == -1, 'lum'] = new_values_lum\n",
    "\n",
    "\n",
    "\"\"\"Delete wrong values\"\"\"\n",
    "\n",
    "carac_df_modif = carac_df_modif.loc[carac_df_modif['int'] != -1]\n",
    "\n",
    "\n",
    "\"\"\"Clean the column 'col'\"\"\"\n",
    "\n",
    "carac_df_modif = carac_df_modif.dropna(subset=['col'])\n",
    "most_frequent = carac_df_modif['col'].mode()[0]\n",
    "carac_df_modif['col'] = carac_df_modif['col'].replace(-1, most_frequent)\n",
    "\n",
    "\n",
    "\"\"\"Clean the column 'atm'\"\"\"\n",
    "\n",
    "carac_df_modif = carac_df_modif.dropna(subset=['atm'])\n",
    "most_frequent = carac_df_modif['atm'].mode()[0]\n",
    "carac_df_modif['atm'] = carac_df_modif['atm'].replace(-1, most_frequent)\n",
    "\n",
    "\n",
    "\"\"\"Clean the column 'com'\"\"\"\n",
    "\n",
    "carac_df_modif = carac_df_modif.dropna(subset=['com'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8462/2902902988.py:2: DtypeWarning:\n",
      "\n",
      "Columns (8,9,20,21,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n",
      "/tmp/ipykernel_8462/2902902988.py:6: DtypeWarning:\n",
      "\n",
      "Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n",
      "/tmp/ipykernel_8462/2902902988.py:7: DtypeWarning:\n",
      "\n",
      "Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## accidents 2005 - 2021\n",
    "data = pd.read_csv(\"../raw_data/Accidents/accidentsVelo.csv\")\n",
    "\n",
    "# data 2022\n",
    "carac_2022 = pd.read_csv('/home/axl/CyclingFacilities/raw_data/Accidents/carcteristiques-2022.csv', sep=\";\")\n",
    "lieux_2022 = pd.read_csv('/home/axl/CyclingFacilities/raw_data/Accidents/lieux-2022.csv', sep=\";\")\n",
    "usagers_2022 = pd.read_csv('/home/axl/CyclingFacilities/raw_data/Accidents/lieux-2022.csv', sep=\";\")\n",
    "vehicule_2022 = pd.read_csv('/home/axl/CyclingFacilities/raw_data/Accidents/vehicules-2022.csv', sep=\";\")\n",
    "\n",
    "all_2022 = carac_2022.merge(lieux_2022, left_on=\"Accident_Id\", right_on=\"Num_Acc\").merge(vehicule_2022, left_on=\"Accident_Id\", right_on=\"Num_Acc\").merge(usagers_2022, left_on=\"Accident_Id\", right_on=\"Num_Acc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Acc</th>\n",
       "      <th>date</th>\n",
       "      <th>an</th>\n",
       "      <th>mois</th>\n",
       "      <th>jour</th>\n",
       "      <th>hrmn</th>\n",
       "      <th>dep</th>\n",
       "      <th>com</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>...</th>\n",
       "      <th>secuexist</th>\n",
       "      <th>equipement</th>\n",
       "      <th>obs</th>\n",
       "      <th>obsm</th>\n",
       "      <th>choc</th>\n",
       "      <th>manv</th>\n",
       "      <th>vehiculeid</th>\n",
       "      <th>typevehicules</th>\n",
       "      <th>manoeuvehicules</th>\n",
       "      <th>numVehicules</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200500000030</td>\n",
       "      <td>2005-01-13</td>\n",
       "      <td>2005</td>\n",
       "      <td>janvier</td>\n",
       "      <td>jeudi</td>\n",
       "      <td>19:45</td>\n",
       "      <td>62</td>\n",
       "      <td>62331</td>\n",
       "      <td>50.3</td>\n",
       "      <td>2.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>200500000030B02</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200500000034</td>\n",
       "      <td>2005-01-19</td>\n",
       "      <td>2005</td>\n",
       "      <td>janvier</td>\n",
       "      <td>mercredi</td>\n",
       "      <td>10:45</td>\n",
       "      <td>62</td>\n",
       "      <td>62022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200500000034B02</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200500000078</td>\n",
       "      <td>2005-01-26</td>\n",
       "      <td>2005</td>\n",
       "      <td>janvier</td>\n",
       "      <td>mercredi</td>\n",
       "      <td>13:15</td>\n",
       "      <td>02</td>\n",
       "      <td>02173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200500000078B02</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200500000093</td>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>2005</td>\n",
       "      <td>janvier</td>\n",
       "      <td>lundi</td>\n",
       "      <td>13:30</td>\n",
       "      <td>02</td>\n",
       "      <td>02810</td>\n",
       "      <td>49.255</td>\n",
       "      <td>3.094</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>200500000093B02</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200500000170</td>\n",
       "      <td>2005-01-29</td>\n",
       "      <td>2005</td>\n",
       "      <td>janvier</td>\n",
       "      <td>samedi</td>\n",
       "      <td>18:30</td>\n",
       "      <td>76</td>\n",
       "      <td>76196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>200500000170A01</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74753</th>\n",
       "      <td>202100056317</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>2021</td>\n",
       "      <td>janvier</td>\n",
       "      <td>samedi</td>\n",
       "      <td>18:30</td>\n",
       "      <td>44</td>\n",
       "      <td>44168</td>\n",
       "      <td>47,3777890000</td>\n",
       "      <td>-2,1976410000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202100056317B01</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74754</th>\n",
       "      <td>202100056362</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021</td>\n",
       "      <td>janvier</td>\n",
       "      <td>lundi</td>\n",
       "      <td>08:20</td>\n",
       "      <td>64</td>\n",
       "      <td>64138</td>\n",
       "      <td>43,2309460000</td>\n",
       "      <td>-0,2765840000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202100056362B01</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74755</th>\n",
       "      <td>202100056404</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021</td>\n",
       "      <td>janvier</td>\n",
       "      <td>vendredi</td>\n",
       "      <td>16:55</td>\n",
       "      <td>54</td>\n",
       "      <td>54395</td>\n",
       "      <td>48,6849869839</td>\n",
       "      <td>6,1760189384</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>202100056404A01</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74756</th>\n",
       "      <td>202100056424</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>2021</td>\n",
       "      <td>janvier</td>\n",
       "      <td>samedi</td>\n",
       "      <td>15:40</td>\n",
       "      <td>75</td>\n",
       "      <td>75110</td>\n",
       "      <td>48,8769050000</td>\n",
       "      <td>2,3665940000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202100056424A01</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74757</th>\n",
       "      <td>202100056508</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021</td>\n",
       "      <td>janvier</td>\n",
       "      <td>vendredi</td>\n",
       "      <td>12:20</td>\n",
       "      <td>64</td>\n",
       "      <td>64400</td>\n",
       "      <td>43,1465730000</td>\n",
       "      <td>-0,1955440000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2/6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202100056508A01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74758 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Num_Acc        date    an     mois      jour   hrmn dep    com  \\\n",
       "0      200500000030  2005-01-13  2005  janvier     jeudi  19:45  62  62331   \n",
       "1      200500000034  2005-01-19  2005  janvier  mercredi  10:45  62  62022   \n",
       "2      200500000078  2005-01-26  2005  janvier  mercredi  13:15  02  02173   \n",
       "3      200500000093  2005-01-03  2005  janvier     lundi  13:30  02  02810   \n",
       "4      200500000170  2005-01-29  2005  janvier    samedi  18:30  76  76196   \n",
       "...             ...         ...   ...      ...       ...    ...  ..    ...   \n",
       "74753  202100056317  2021-01-02  2021  janvier    samedi  18:30  44  44168   \n",
       "74754  202100056362  2021-01-04  2021  janvier     lundi  08:20  64  64138   \n",
       "74755  202100056404  2021-01-01  2021  janvier  vendredi  16:55  54  54395   \n",
       "74756  202100056424  2021-01-02  2021  janvier    samedi  15:40  75  75110   \n",
       "74757  202100056508  2021-01-01  2021  janvier  vendredi  12:20  64  64400   \n",
       "\n",
       "                 lat            long  ...  secuexist  equipement  obs  obsm  \\\n",
       "0               50.3            2.84  ...          0           0  0.0   2.0   \n",
       "1                0.0             0.0  ...          0           0  0.0   2.0   \n",
       "2                0.0             0.0  ...          1           2  0.0   2.0   \n",
       "3             49.255           3.094  ...          0           0  0.0   2.0   \n",
       "4                0.0             0.0  ...          1           9  0.0   2.0   \n",
       "...              ...             ...  ...        ...         ...  ...   ...   \n",
       "74753  47,3777890000   -2,1976410000  ...          2         NaN  0.0   0.0   \n",
       "74754  43,2309460000   -0,2765840000  ...          1           2  0.0   2.0   \n",
       "74755  48,6849869839    6,1760189384  ...          1           2  0.0   2.0   \n",
       "74756  48,8769050000    2,3665940000  ...          2         NaN  0.0   2.0   \n",
       "74757  43,1465730000   -0,1955440000  ...          1         2/6  0.0   0.0   \n",
       "\n",
       "       choc  manv       vehiculeid  typevehicules  manoeuvehicules  \\\n",
       "0       8.0  11.0  200500000030B02             18               17   \n",
       "1       1.0   1.0  200500000034B02             10               15   \n",
       "2       1.0   1.0  200500000078B02              7               15   \n",
       "3       3.0  21.0  200500000093B02              7               21   \n",
       "4       4.0   2.0  200500000170A01             10                2   \n",
       "...     ...   ...              ...            ...              ...   \n",
       "74753   8.0   1.0  202100056317B01              7               14   \n",
       "74754   0.0   1.0  202100056362B01              7               15   \n",
       "74755   1.0  25.0  202100056404A01              7                1   \n",
       "74756   1.0   1.0  202100056424A01              7                9   \n",
       "74757   8.0   1.0  202100056508A01            NaN              NaN   \n",
       "\n",
       "       numVehicules  \n",
       "0               1.0  \n",
       "1               1.0  \n",
       "2               1.0  \n",
       "3               1.0  \n",
       "4               1.0  \n",
       "...             ...  \n",
       "74753           1.0  \n",
       "74754           1.0  \n",
       "74755           1.0  \n",
       "74756           1.0  \n",
       "74757           NaN  \n",
       "\n",
       "[74758 rows x 39 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bikes_2022 = all_2022[all_2022.catv == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8462/3338634255.py:1: FutureWarning:\n",
      "\n",
      "Passing 'suffixes' which cause duplicate columns {'Num_Acc_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accident_Id</th>\n",
       "      <th>jour_x</th>\n",
       "      <th>mois_x</th>\n",
       "      <th>an_x</th>\n",
       "      <th>hrmn_x</th>\n",
       "      <th>lum_x</th>\n",
       "      <th>dep_x</th>\n",
       "      <th>com_x</th>\n",
       "      <th>agg_x</th>\n",
       "      <th>int_x</th>\n",
       "      <th>...</th>\n",
       "      <th>secuexist</th>\n",
       "      <th>equipement</th>\n",
       "      <th>obs_y</th>\n",
       "      <th>obsm_y</th>\n",
       "      <th>choc_y</th>\n",
       "      <th>manv_y</th>\n",
       "      <th>vehiculeid</th>\n",
       "      <th>typevehicules</th>\n",
       "      <th>manoeuvehicules</th>\n",
       "      <th>numVehicules</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Accident_Id, jour_x, mois_x, an_x, hrmn_x, lum_x, dep_x, com_x, agg_x, int_x, atm_x, col_x, adr, lat_x, long_x, Num_Acc_x, catr_x, voie_x, v1_x, v2_x, circ_x, nbv_x, vosp_x, prof_x, pr_x, pr1_x, plan_x, lartpc_x, larrout_x, surf_x, infra_x, situ_x, vma_x, Num_Acc_y, id_vehicule, num_veh, senc, catv, obs_x, obsm_x, choc_x, manv_x, motor, occutc, Num_Acc_x, catr_y, voie_y, v1_y, v2_y, circ_y, nbv_y, vosp_y, prof_y, pr_y, pr1_y, plan_y, lartpc_y, larrout_y, surf_y, infra_y, situ_y, vma_y, Num_Acc_y, date, an_y, mois_y, jour_y, hrmn_y, dep_y, com_y, lat_y, long_y, agg_y, int_y, col_y, lum_y, atm_y, catr, circ, nbv, prof, plan, lartpc, larrout, surf, infra, situ, grav, sexe, age, trajet, secuexist, equipement, obs_y, obsm_y, choc_y, manv_y, vehiculeid, typevehicules, manoeuvehicules, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 101 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bikes_2022.merge(data, left_on=\"Accident_Id\", right_on=\"Num_Acc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8462/2098982804.py:1: FutureWarning:\n",
      "\n",
      "Passing 'suffixes' which cause duplicate columns {'Num_Acc_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accident_Id</th>\n",
       "      <th>jour_x</th>\n",
       "      <th>mois_x</th>\n",
       "      <th>an_x</th>\n",
       "      <th>hrmn_x</th>\n",
       "      <th>lum_x</th>\n",
       "      <th>dep_x</th>\n",
       "      <th>com_x</th>\n",
       "      <th>agg_x</th>\n",
       "      <th>int_x</th>\n",
       "      <th>...</th>\n",
       "      <th>secuexist</th>\n",
       "      <th>equipement</th>\n",
       "      <th>obs_y</th>\n",
       "      <th>obsm_y</th>\n",
       "      <th>choc_y</th>\n",
       "      <th>manv_y</th>\n",
       "      <th>vehiculeid</th>\n",
       "      <th>typevehicules</th>\n",
       "      <th>manoeuvehicules</th>\n",
       "      <th>numVehicules</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.022000e+11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>16:32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75</td>\n",
       "      <td>75106</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.022000e+11</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>13:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75</td>\n",
       "      <td>75105</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.022000e+11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>11:25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75</td>\n",
       "      <td>75113</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.022000e+11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>15:50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75</td>\n",
       "      <td>75103</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.022000e+11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>19:40</td>\n",
       "      <td>5.0</td>\n",
       "      <td>93</td>\n",
       "      <td>93049</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80073</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202100056317B01</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80074</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202100056362B01</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80075</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>202100056404A01</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80076</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202100056424A01</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80077</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2/6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202100056508A01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80078 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accident_Id  jour_x  mois_x    an_x hrmn_x  lum_x dep_x  com_x  agg_x  \\\n",
       "0      2.022000e+11    21.0    10.0  2022.0  16:32    1.0    75  75106    2.0   \n",
       "1      2.022000e+11    20.0    10.0  2022.0  13:00    1.0    75  75105    2.0   \n",
       "2      2.022000e+11    21.0    10.0  2022.0  11:25    1.0    75  75113    2.0   \n",
       "3      2.022000e+11    21.0    10.0  2022.0  15:50    1.0    75  75103    2.0   \n",
       "4      2.022000e+11    21.0    10.0  2022.0  19:40    5.0    93  93049    2.0   \n",
       "...             ...     ...     ...     ...    ...    ...   ...    ...    ...   \n",
       "80073           NaN     NaN     NaN     NaN    NaN    NaN   NaN    NaN    NaN   \n",
       "80074           NaN     NaN     NaN     NaN    NaN    NaN   NaN    NaN    NaN   \n",
       "80075           NaN     NaN     NaN     NaN    NaN    NaN   NaN    NaN    NaN   \n",
       "80076           NaN     NaN     NaN     NaN    NaN    NaN   NaN    NaN    NaN   \n",
       "80077           NaN     NaN     NaN     NaN    NaN    NaN   NaN    NaN    NaN   \n",
       "\n",
       "       int_x  ...  secuexist  equipement obs_y obsm_y choc_y  manv_y  \\\n",
       "0        1.0  ...        NaN         NaN   NaN    NaN    NaN     NaN   \n",
       "1        2.0  ...        NaN         NaN   NaN    NaN    NaN     NaN   \n",
       "2        4.0  ...        NaN         NaN   NaN    NaN    NaN     NaN   \n",
       "3        2.0  ...        NaN         NaN   NaN    NaN    NaN     NaN   \n",
       "4        2.0  ...        NaN         NaN   NaN    NaN    NaN     NaN   \n",
       "...      ...  ...        ...         ...   ...    ...    ...     ...   \n",
       "80073    NaN  ...        2.0         NaN   0.0    0.0    8.0     1.0   \n",
       "80074    NaN  ...        1.0           2   0.0    2.0    0.0     1.0   \n",
       "80075    NaN  ...        1.0           2   0.0    2.0    1.0    25.0   \n",
       "80076    NaN  ...        2.0         NaN   0.0    2.0    1.0     1.0   \n",
       "80077    NaN  ...        1.0         2/6   0.0    0.0    8.0     1.0   \n",
       "\n",
       "            vehiculeid typevehicules  manoeuvehicules numVehicules  \n",
       "0                  NaN           NaN              NaN          NaN  \n",
       "1                  NaN           NaN              NaN          NaN  \n",
       "2                  NaN           NaN              NaN          NaN  \n",
       "3                  NaN           NaN              NaN          NaN  \n",
       "4                  NaN           NaN              NaN          NaN  \n",
       "...                ...           ...              ...          ...  \n",
       "80073  202100056317B01             7               14          1.0  \n",
       "80074  202100056362B01             7               15          1.0  \n",
       "80075  202100056404A01             7                1          1.0  \n",
       "80076  202100056424A01             7                9          1.0  \n",
       "80077  202100056508A01           NaN              NaN          NaN  \n",
       "\n",
       "[80078 rows x 101 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_bikes_2022.merge(data, how='outer', left_on=\"Accident_Id\", right_on=\"Num_Acc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.query('lat != 0 & long != 0').reset_index(drop=True)\n",
    "data.dep.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['13'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paris_df = data[data.dep == \"75\"]\n",
    "mars_df = data[data.dep == \"13\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Acc</th>\n",
       "      <th>date</th>\n",
       "      <th>an</th>\n",
       "      <th>mois</th>\n",
       "      <th>jour</th>\n",
       "      <th>hrmn</th>\n",
       "      <th>dep</th>\n",
       "      <th>com</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>...</th>\n",
       "      <th>secuexist</th>\n",
       "      <th>equipement</th>\n",
       "      <th>obs</th>\n",
       "      <th>obsm</th>\n",
       "      <th>choc</th>\n",
       "      <th>manv</th>\n",
       "      <th>vehiculeid</th>\n",
       "      <th>typevehicules</th>\n",
       "      <th>manoeuvehicules</th>\n",
       "      <th>numVehicules</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>201000062968</td>\n",
       "      <td>2010-10-03</td>\n",
       "      <td>2010</td>\n",
       "      <td>octobre</td>\n",
       "      <td>dimanche</td>\n",
       "      <td>18:45</td>\n",
       "      <td>75</td>\n",
       "      <td>75112</td>\n",
       "      <td>48.83464</td>\n",
       "      <td>2.43893</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>201000062968A01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3914</th>\n",
       "      <td>201000062968</td>\n",
       "      <td>2010-10-03</td>\n",
       "      <td>2010</td>\n",
       "      <td>octobre</td>\n",
       "      <td>dimanche</td>\n",
       "      <td>18:45</td>\n",
       "      <td>75</td>\n",
       "      <td>75112</td>\n",
       "      <td>48.83464</td>\n",
       "      <td>2.43893</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201000062968B01</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12273</th>\n",
       "      <td>201500050797</td>\n",
       "      <td>2015-06-23</td>\n",
       "      <td>2015</td>\n",
       "      <td>juin</td>\n",
       "      <td>mardi</td>\n",
       "      <td>18:30</td>\n",
       "      <td>75</td>\n",
       "      <td>75103</td>\n",
       "      <td>48.52011</td>\n",
       "      <td>2.21485</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>201500050797A01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12274</th>\n",
       "      <td>201500052215</td>\n",
       "      <td>2015-08-13</td>\n",
       "      <td>2015</td>\n",
       "      <td>août</td>\n",
       "      <td>jeudi</td>\n",
       "      <td>20:30</td>\n",
       "      <td>75</td>\n",
       "      <td>75110</td>\n",
       "      <td>48.52501</td>\n",
       "      <td>2.21432</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>201500052215A01</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12275</th>\n",
       "      <td>201500055885</td>\n",
       "      <td>2015-06-27</td>\n",
       "      <td>2015</td>\n",
       "      <td>juin</td>\n",
       "      <td>samedi</td>\n",
       "      <td>14:20</td>\n",
       "      <td>75</td>\n",
       "      <td>75118</td>\n",
       "      <td>48.53181</td>\n",
       "      <td>2.2107</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>201500055885B01</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31614</th>\n",
       "      <td>202100056069</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>2021</td>\n",
       "      <td>janvier</td>\n",
       "      <td>mercredi</td>\n",
       "      <td>16:15</td>\n",
       "      <td>75</td>\n",
       "      <td>75112</td>\n",
       "      <td>48,8446739656</td>\n",
       "      <td>2,4057128628</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202100056069B01</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31616</th>\n",
       "      <td>202100056184</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021</td>\n",
       "      <td>janvier</td>\n",
       "      <td>lundi</td>\n",
       "      <td>17:35</td>\n",
       "      <td>75</td>\n",
       "      <td>75103</td>\n",
       "      <td>48,8623960000</td>\n",
       "      <td>2,3555220000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>202100056184A01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31618</th>\n",
       "      <td>202100056276</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021</td>\n",
       "      <td>janvier</td>\n",
       "      <td>lundi</td>\n",
       "      <td>18:25</td>\n",
       "      <td>75</td>\n",
       "      <td>75119</td>\n",
       "      <td>48,8816830000</td>\n",
       "      <td>2,3810550000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2/6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202100056276B01</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31619</th>\n",
       "      <td>202100056283</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021</td>\n",
       "      <td>janvier</td>\n",
       "      <td>lundi</td>\n",
       "      <td>19:40</td>\n",
       "      <td>75</td>\n",
       "      <td>75101</td>\n",
       "      <td>48,8649640000</td>\n",
       "      <td>2,3347680000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202100056283A01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31626</th>\n",
       "      <td>202100056424</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>2021</td>\n",
       "      <td>janvier</td>\n",
       "      <td>samedi</td>\n",
       "      <td>15:40</td>\n",
       "      <td>75</td>\n",
       "      <td>75110</td>\n",
       "      <td>48,8769050000</td>\n",
       "      <td>2,3665940000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202100056424A01</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5019 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Num_Acc        date    an     mois      jour   hrmn dep    com  \\\n",
       "3913   201000062968  2010-10-03  2010  octobre  dimanche  18:45  75  75112   \n",
       "3914   201000062968  2010-10-03  2010  octobre  dimanche  18:45  75  75112   \n",
       "12273  201500050797  2015-06-23  2015     juin     mardi  18:30  75  75103   \n",
       "12274  201500052215  2015-08-13  2015     août     jeudi  20:30  75  75110   \n",
       "12275  201500055885  2015-06-27  2015     juin    samedi  14:20  75  75118   \n",
       "...             ...         ...   ...      ...       ...    ...  ..    ...   \n",
       "31614  202100056069  2021-01-06  2021  janvier  mercredi  16:15  75  75112   \n",
       "31616  202100056184  2021-01-04  2021  janvier     lundi  17:35  75  75103   \n",
       "31618  202100056276  2021-01-04  2021  janvier     lundi  18:25  75  75119   \n",
       "31619  202100056283  2021-01-04  2021  janvier     lundi  19:40  75  75101   \n",
       "31626  202100056424  2021-01-02  2021  janvier    samedi  15:40  75  75110   \n",
       "\n",
       "                 lat          long  ...  secuexist  equipement  obs  obsm  \\\n",
       "3913        48.83464       2.43893  ...          1           2  0.0   0.0   \n",
       "3914        48.83464       2.43893  ...          1           2  0.0   0.0   \n",
       "12273       48.52011       2.21485  ...          1           2  0.0   1.0   \n",
       "12274       48.52501       2.21432  ...          1           2  0.0   2.0   \n",
       "12275       48.53181        2.2107  ...          1           2  0.0   0.0   \n",
       "...              ...           ...  ...        ...         ...  ...   ...   \n",
       "31614  48,8446739656  2,4057128628  ...          2         NaN  0.0   2.0   \n",
       "31616  48,8623960000  2,3555220000  ...          1           2  0.0   0.0   \n",
       "31618  48,8816830000  2,3810550000  ...          1         2/6  0.0   2.0   \n",
       "31619  48,8649640000  2,3347680000  ...          2         NaN  0.0   1.0   \n",
       "31626  48,8769050000  2,3665940000  ...          2         NaN  0.0   2.0   \n",
       "\n",
       "       choc  manv       vehiculeid  typevehicules  manoeuvehicules  \\\n",
       "3913    5.0  17.0  201000062968A01              1                1   \n",
       "3914    3.0   1.0  201000062968B01              1               17   \n",
       "12273   1.0   3.0  201500050797A01            NaN              NaN   \n",
       "12274   0.0   1.0  201500052215A01             31                1   \n",
       "12275   7.0  18.0  201500055885B01              7               22   \n",
       "...     ...   ...              ...            ...              ...   \n",
       "31614   8.0   1.0  202100056069B01              7               14   \n",
       "31616   1.0  21.0  202100056184A01            NaN              NaN   \n",
       "31618   3.0   1.0  202100056276B01              7               17   \n",
       "31619   1.0   1.0  202100056283A01            NaN              NaN   \n",
       "31626   1.0   1.0  202100056424A01              7                9   \n",
       "\n",
       "       numVehicules  \n",
       "3913            1.0  \n",
       "3914            1.0  \n",
       "12273           NaN  \n",
       "12274           1.0  \n",
       "12275           1.0  \n",
       "...             ...  \n",
       "31614           1.0  \n",
       "31616           NaN  \n",
       "31618           1.0  \n",
       "31619           NaN  \n",
       "31626           1.0  \n",
       "\n",
       "[5019 rows x 39 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paris_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Num_Acc', 'date', 'an', 'mois', 'jour', 'hrmn', 'dep', 'com', 'lat',\n",
       "       'long', 'agg', 'int', 'col', 'lum', 'atm', 'catr', 'circ', 'nbv',\n",
       "       'prof', 'plan', 'lartpc', 'larrout', 'surf', 'infra', 'situ', 'grav',\n",
       "       'sexe', 'age', 'trajet', 'secuexist', 'equipement', 'obs', 'obsm',\n",
       "       'choc', 'manv', 'vehiculeid', 'typevehicules', 'manoeuvehicules',\n",
       "       'numVehicules'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Acc</th>\n",
       "      <th>date</th>\n",
       "      <th>an</th>\n",
       "      <th>mois</th>\n",
       "      <th>jour</th>\n",
       "      <th>hrmn</th>\n",
       "      <th>dep</th>\n",
       "      <th>com</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>...</th>\n",
       "      <th>secuexist</th>\n",
       "      <th>equipement</th>\n",
       "      <th>obs</th>\n",
       "      <th>obsm</th>\n",
       "      <th>choc</th>\n",
       "      <th>manv</th>\n",
       "      <th>vehiculeid</th>\n",
       "      <th>typevehicules</th>\n",
       "      <th>manoeuvehicules</th>\n",
       "      <th>numVehicules</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>200500026234</td>\n",
       "      <td>2005-05-05</td>\n",
       "      <td>2005</td>\n",
       "      <td>mai</td>\n",
       "      <td>jeudi</td>\n",
       "      <td>14:15</td>\n",
       "      <td>13</td>\n",
       "      <td>13110</td>\n",
       "      <td>43.449</td>\n",
       "      <td>5.689</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>200500026234B02</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>200500026972</td>\n",
       "      <td>2005-05-12</td>\n",
       "      <td>2005</td>\n",
       "      <td>mai</td>\n",
       "      <td>jeudi</td>\n",
       "      <td>12:15</td>\n",
       "      <td>13</td>\n",
       "      <td>13113</td>\n",
       "      <td>43.6</td>\n",
       "      <td>5.48</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200500026972B02</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>200500027020</td>\n",
       "      <td>2005-05-11</td>\n",
       "      <td>2005</td>\n",
       "      <td>mai</td>\n",
       "      <td>mercredi</td>\n",
       "      <td>14:15</td>\n",
       "      <td>13</td>\n",
       "      <td>13083</td>\n",
       "      <td>43.916</td>\n",
       "      <td>4.808</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200500027020A01</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>200500039391</td>\n",
       "      <td>2005-06-01</td>\n",
       "      <td>2005</td>\n",
       "      <td>juin</td>\n",
       "      <td>mercredi</td>\n",
       "      <td>19:30</td>\n",
       "      <td>13</td>\n",
       "      <td>13019</td>\n",
       "      <td>43.445</td>\n",
       "      <td>5.362</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200500039391B02</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>200500039402</td>\n",
       "      <td>2005-06-24</td>\n",
       "      <td>2005</td>\n",
       "      <td>juin</td>\n",
       "      <td>vendredi</td>\n",
       "      <td>16:15</td>\n",
       "      <td>13</td>\n",
       "      <td>13027</td>\n",
       "      <td>43.896</td>\n",
       "      <td>4.832</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>200500039402A01</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30867</th>\n",
       "      <td>202100042976</td>\n",
       "      <td>2021-04-24</td>\n",
       "      <td>2021</td>\n",
       "      <td>avril</td>\n",
       "      <td>samedi</td>\n",
       "      <td>07:45</td>\n",
       "      <td>13</td>\n",
       "      <td>13032</td>\n",
       "      <td>43,5779040000</td>\n",
       "      <td>5,3365450000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202100042976B01</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30868</th>\n",
       "      <td>202100042976</td>\n",
       "      <td>2021-04-24</td>\n",
       "      <td>2021</td>\n",
       "      <td>avril</td>\n",
       "      <td>samedi</td>\n",
       "      <td>07:45</td>\n",
       "      <td>13</td>\n",
       "      <td>13032</td>\n",
       "      <td>43,5779040000</td>\n",
       "      <td>5,3365450000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202100042976C01</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31033</th>\n",
       "      <td>202100045502</td>\n",
       "      <td>2021-04-02</td>\n",
       "      <td>2021</td>\n",
       "      <td>avril</td>\n",
       "      <td>vendredi</td>\n",
       "      <td>12:25</td>\n",
       "      <td>13</td>\n",
       "      <td>13015</td>\n",
       "      <td>43,4573580000</td>\n",
       "      <td>5,4130790000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202100045502B01</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31228</th>\n",
       "      <td>202100048088</td>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>2021</td>\n",
       "      <td>mars</td>\n",
       "      <td>lundi</td>\n",
       "      <td>08:50</td>\n",
       "      <td>13</td>\n",
       "      <td>13100</td>\n",
       "      <td>43,7922950000</td>\n",
       "      <td>4,8394720000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>202100048088B01</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31275</th>\n",
       "      <td>202100048899</td>\n",
       "      <td>2021-03-07</td>\n",
       "      <td>2021</td>\n",
       "      <td>mars</td>\n",
       "      <td>dimanche</td>\n",
       "      <td>16:00</td>\n",
       "      <td>13</td>\n",
       "      <td>13011</td>\n",
       "      <td>43,7347820000</td>\n",
       "      <td>4,8211690000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202100048899B01</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>586 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Num_Acc        date    an   mois      jour   hrmn dep    com  \\\n",
       "209    200500026234  2005-05-05  2005    mai     jeudi  14:15  13  13110   \n",
       "226    200500026972  2005-05-12  2005    mai     jeudi  12:15  13  13113   \n",
       "227    200500027020  2005-05-11  2005    mai  mercredi  14:15  13  13083   \n",
       "294    200500039391  2005-06-01  2005   juin  mercredi  19:30  13  13019   \n",
       "295    200500039402  2005-06-24  2005   juin  vendredi  16:15  13  13027   \n",
       "...             ...         ...   ...    ...       ...    ...  ..    ...   \n",
       "30867  202100042976  2021-04-24  2021  avril    samedi  07:45  13  13032   \n",
       "30868  202100042976  2021-04-24  2021  avril    samedi  07:45  13  13032   \n",
       "31033  202100045502  2021-04-02  2021  avril  vendredi  12:25  13  13015   \n",
       "31228  202100048088  2021-03-15  2021   mars     lundi  08:50  13  13100   \n",
       "31275  202100048899  2021-03-07  2021   mars  dimanche  16:00  13  13011   \n",
       "\n",
       "                 lat          long  ...  secuexist  equipement  obs  obsm  \\\n",
       "209           43.449         5.689  ...          0           0  0.0   2.0   \n",
       "226             43.6          5.48  ...          1           2  0.0   2.0   \n",
       "227           43.916         4.808  ...          1           2  0.0   2.0   \n",
       "294           43.445         5.362  ...          0           0  0.0   2.0   \n",
       "295           43.896         4.832  ...          1           4  0.0   2.0   \n",
       "...              ...           ...  ...        ...         ...  ...   ...   \n",
       "30867  43,5779040000  5,3365450000  ...          1           2  0.0   2.0   \n",
       "30868  43,5779040000  5,3365450000  ...          1           2  0.0   2.0   \n",
       "31033  43,4573580000  5,4130790000  ...          1           2  0.0   2.0   \n",
       "31228  43,7922950000  4,8394720000  ...          2         NaN  0.0   0.0   \n",
       "31275  43,7347820000  4,8211690000  ...          2         NaN  0.0   2.0   \n",
       "\n",
       "       choc  manv       vehiculeid  typevehicules  manoeuvehicules  \\\n",
       "209     1.0   5.0  200500026234B02              7                1   \n",
       "226     1.0   1.0  200500026972B02              7               15   \n",
       "227     1.0   1.0  200500027020A01              7                1   \n",
       "294     1.0   1.0  200500039391B02              7               16   \n",
       "295     8.0  13.0  200500039402A01             15               17   \n",
       "...     ...   ...              ...            ...              ...   \n",
       "30867   1.0   1.0  202100042976B01              7               17   \n",
       "30868   0.0   1.0  202100042976C01              7               17   \n",
       "31033   1.0   1.0  202100045502B01              7               15   \n",
       "31228   4.0  19.0  202100048088B01              7                1   \n",
       "31275   1.0   1.0  202100048899B01              7               15   \n",
       "\n",
       "       numVehicules  \n",
       "209             1.0  \n",
       "226             1.0  \n",
       "227             1.0  \n",
       "294             1.0  \n",
       "295             1.0  \n",
       "...             ...  \n",
       "30867           1.0  \n",
       "30868           1.0  \n",
       "31033           1.0  \n",
       "31228           1.0  \n",
       "31275           1.0  \n",
       "\n",
       "[586 rows x 39 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mpx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_mapbox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmars_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlong\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzoom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmars_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgrav\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapbox_style\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcarto-positron\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_layout(\n\u001b[1;32m     12\u001b[0m     margin\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m10\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m10\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m10\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m10\u001b[39m}  \u001b[38;5;66;03m# Marges droite, haut, gauche, bas à 0\u001b[39;00m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/plotly/express/_chart_types.py:1247\u001b[0m, in \u001b[0;36mscatter_mapbox\u001b[0;34m(data_frame, lat, lon, color, text, hover_name, hover_data, custom_data, size, animation_frame, animation_group, category_orders, labels, color_discrete_sequence, color_discrete_map, color_continuous_scale, range_color, color_continuous_midpoint, opacity, size_max, zoom, center, mapbox_style, title, template, width, height)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter_mapbox\u001b[39m(\n\u001b[1;32m   1215\u001b[0m     data_frame\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1216\u001b[0m     lat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1241\u001b[0m     height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1242\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;124;03m    In a Mapbox scatter plot, each row of `data_frame` is represented by a\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;124;03m    symbol mark on a Mapbox map.\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstructor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScattermapbox\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/plotly/express/_core.py:2277\u001b[0m, in \u001b[0;36mmake_figure\u001b[0;34m(args, constructor, trace_patch, layout_patch)\u001b[0m\n\u001b[1;32m   2273\u001b[0m         trendline_rows\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mdict\u001b[39m(px_fit_results\u001b[38;5;241m=\u001b[39mfit_results))\n\u001b[1;32m   2275\u001b[0m fig\u001b[38;5;241m.\u001b[39m_px_trendlines \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(trendline_rows)\n\u001b[0;32m-> 2277\u001b[0m \u001b[43mconfigure_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstructor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2278\u001b[0m configure_animation_controls(args, constructor, fig)\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fig\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/plotly/express/_core.py:541\u001b[0m, in \u001b[0;36mconfigure_axes\u001b[0;34m(args, constructor, fig, orders)\u001b[0m\n\u001b[1;32m    539\u001b[0m     configurators[c] \u001b[38;5;241m=\u001b[39m configure_cartesian_axes\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m constructor \u001b[38;5;129;01min\u001b[39;00m configurators:\n\u001b[0;32m--> 541\u001b[0m     \u001b[43mconfigurators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconstructor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morders\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/plotly/express/_core.py:729\u001b[0m, in \u001b[0;36mconfigure_mapbox\u001b[0;34m(args, fig, orders)\u001b[0m\n\u001b[1;32m    726\u001b[0m center \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m center \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args:\n\u001b[1;32m    728\u001b[0m     center \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m--> 729\u001b[0m         lat\u001b[38;5;241m=\u001b[39m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_frame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    730\u001b[0m         lon\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_frame\u001b[39m\u001b[38;5;124m\"\u001b[39m][args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mmean(),\n\u001b[1;32m    731\u001b[0m     )\n\u001b[1;32m    732\u001b[0m fig\u001b[38;5;241m.\u001b[39mupdate_mapboxes(\n\u001b[1;32m    733\u001b[0m     accesstoken\u001b[38;5;241m=\u001b[39mMAPBOX_TOKEN,\n\u001b[1;32m    734\u001b[0m     center\u001b[38;5;241m=\u001b[39mcenter,\n\u001b[1;32m    735\u001b[0m     zoom\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzoom\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    736\u001b[0m     style\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmapbox_style\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    737\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/generic.py:11124\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11106\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11107\u001b[0m     _num_doc,\n\u001b[1;32m  11108\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11122\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11123\u001b[0m ):\n\u001b[0;32m> 11124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/generic.py:10694\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  10686\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  10687\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10688\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10692\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  10693\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 10694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10695\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  10696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/generic.py:10646\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  10636\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  10637\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  10638\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10641\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  10642\u001b[0m     )\n\u001b[1;32m  10643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  10644\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  10645\u001b[0m     )\n\u001b[0;32m> 10646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  10648\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/series.py:4471\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4468\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4469\u001b[0m     )\n\u001b[1;32m   4470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/nanops.py:410\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 410\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    413\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/pandas/core/nanops.py:698\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    695\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    697\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 698\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    701\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "fig = px.scatter_mapbox(\n",
    "    mars_df,\n",
    "    lat='lat',\n",
    "    lon='long',\n",
    "    height=600,\n",
    "    zoom=12,\n",
    "    color=mars_df['grav'],\n",
    "    mapbox_style=\"carto-positron\",\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    margin={\"r\":10,\"t\":10,\"l\":10,\"b\":10}  # Marges droite, haut, gauche, bas à 0\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
