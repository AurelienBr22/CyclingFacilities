{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import requests\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggrégation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = \"../raw_data/year_data/\"\n",
    "# dff = []\n",
    "# files = [file for file in os.listdir(folder) if file.endswith('.csv')]\n",
    "# for file in files:\n",
    "#     file_path = os.path.join(folder, file)\n",
    "#     if file in ['caracteristiques_2018.csv', 'caracteristiques_2008.csv',\n",
    "#                 'caracteristiques_2011.csv','caracteristiques_2010.csv',\n",
    "#                 'caracteristiques_2005.csv','caracteristiques_2006.csv',\n",
    "#                 'caracteristiques_2007.csv',\n",
    "#                 'caracteristiques_2013.csv','caracteristiques_2012.csv',\n",
    "#                 'caracteristiques_2014.csv','caracteristiques_2015.csv',\n",
    "#                 'caracteristiques_2016.csv','caracteristiques_2017.csv']:\n",
    "#         encoding = 'latin-1'\n",
    "#         sep = ','\n",
    "#     elif file in ['caracteristiques_2009.csv']:\n",
    "#         encoding = 'latin-1'\n",
    "#         sep = '\\t'\n",
    "#     elif file in ['vehicules_2019.csv','vehicules_2020.csv','vehicules_2021.csv','vehicules_2022.csv','lieux_2019.csv','lieux_2020.csv','lieux_2021.csv',\n",
    "#                   'lieux_2022.csv','caracteristiques_2019.csv',\n",
    "#                   'caracteristiques_2021.csv','caracteristiques_2022.csv',\n",
    "#                   'caracteristiques_2020.csv' ]:\n",
    "#         encoding = 'latin-1'\n",
    "\n",
    "#         sep = ';'\n",
    "#     elif file in ['2019.csv', '2020.csv', '2021.csv', '2022.csv']:\n",
    "#         sep = ';'\n",
    "#         encoding = 'latin-1'\n",
    "#     else:\n",
    "#         sep = ','\n",
    "#         encoding = 'utf-8'\n",
    "#     print(file_path)\n",
    "#     df = pd.read_csv(file_path, sep=sep, encoding=encoding)\n",
    "#     # df = df.applymap(lambda x: str(x).replace('\"', ''))\n",
    "#     dff.append(df)\n",
    "#     df_chiant = pd.concat(dff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API POUR REQUEST & SAVE URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### call api for datasets urls\n",
    "\n",
    "\n",
    "def get_datasets_url(url=None):\n",
    "    url ='https://www.data.gouv.fr/api/1/datasets/53698f4ca3a729239d2036df/'\n",
    "    r = requests.get(url).json()\n",
    "    return {el['title']: el['latest'] for el in r['resources'] if el['title'].endswith(\".csv\") and not el['title'].startswith(\"vehicules-immatricules\") }\n",
    "\n",
    "lieux_datasets = {i:j for i,j in get_datasets_url().items() if i.startswith(\"lieux\")}\n",
    "usagers_datasets = {i:j for i,j in get_datasets_url().items() if i.startswith(\"usagers\")}\n",
    "car_datasets = {i:j for i,j in get_datasets_url().items() if i.startswith(\"car\")}\n",
    "vehicule_datasets = {i:j for i,j in get_datasets_url().items() if i.startswith(\"vehicule\")}\n",
    "\n",
    "all_urls = [lieux_datasets, usagers_datasets, car_datasets,vehicule_datasets]\n",
    "\n",
    "### download csvs if not already\n",
    "\n",
    "for url_dict in all_urls:\n",
    "    for path, url in url_dict.items():\n",
    "        path = '../raw_data/' + path\n",
    "        if not os.path.exists(path):\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                with open(path, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "\n",
    "### check datasets\n",
    "\n",
    "folder = \"../raw_data/\"\n",
    "os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemin_fichier_yml = '../config.yml'\n",
    "chemin_dossier = '../raw_data/'\n",
    "\n",
    "\n",
    "with open (chemin_fichier_yml, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    rename_config = config.get('rename')\n",
    "\n",
    "for old_name, new_name in rename_config.items():\n",
    "    chemin_ancien_fichier = os.path.join(chemin_dossier, old_name)\n",
    "    chemin_nouveau_fichier = os.path.join(chemin_dossier, new_name)\n",
    "\n",
    "    if os.path.exists(chemin_ancien_fichier):\n",
    "        os.rename(chemin_ancien_fichier, chemin_nouveau_fichier)\n",
    "        print(f\"Fichier renommé : {old_name} -> {new_name}\")\n",
    "    else:\n",
    "        print(f\"Fichier non trouvé : {old_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def concat_files(starting_word):\n",
    "\n",
    "    chemin_fichier_yml = '../config.yml'\n",
    "    with open(chemin_fichier_yml, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "        config_sep = config.get('sep')\n",
    "        config_encoding = config.get('encoding')\n",
    "\n",
    "    chemin_dossier = '../raw_data/'\n",
    "\n",
    "    df_concat = pd.DataFrame()\n",
    "    files = [file for file in os.listdir(chemin_dossier) if file.endswith('.csv') and file.startswith(starting_word)]\n",
    "\n",
    "    print(files)\n",
    "    for file in files:\n",
    "        chemin_fichier = os.path.join(chemin_dossier, file)\n",
    "\n",
    "        if file in config_sep:\n",
    "            sep = config_sep[file]\n",
    "        else:\n",
    "            sep = ','\n",
    "\n",
    "        if file in config_encoding:\n",
    "            encoding = config_encoding[file]\n",
    "        else:\n",
    "            encoding = 'utf-8'\n",
    "\n",
    "        df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n",
    "\n",
    "        df_concat = pd.concat([df_concat, df1])\n",
    "\n",
    "    return df_concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['caracteristiques_2018.csv', 'caracteristiques_2019.csv', 'caracteristiques_2022.csv', 'caracteristiques_2009.csv', 'caracteristiques_2021.csv', 'caracteristiques_2020.csv', 'caracteristiques_2008.csv', 'caracteristiques_2011.csv', 'caracteristiques_2005.csv', 'caracteristiques_2010.csv', 'caracteristiques_2006.csv', 'caracteristiques_2012.csv', 'caracteristiques_2013.csv', 'caracteristiques_2007.csv', 'caracteristiques_2017.csv', 'caracteristiques_2016.csv', 'caracteristiques_2014.csv', 'caracteristiques_2015.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jw/qw353j7x7h970k1t74h_j5nc0000gn/T/ipykernel_9220/241619552.py:28: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lieux_2017.csv', 'lieux_2016.csv', 'lieux_2014.csv', 'lieux_2015.csv', 'lieux_2011.csv', 'lieux_2005.csv', 'lieux_2010.csv', 'lieux_2006.csv', 'lieux_2012.csv', 'lieux_2013.csv', 'lieux_2007.csv', 'lieux_2022.csv', 'lieux_2009.csv', 'lieux_2021.csv', 'lieux_2020.csv', 'lieux_2008.csv', 'lieux_2018.csv', 'lieux_2019.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jw/qw353j7x7h970k1t74h_j5nc0000gn/T/ipykernel_9220/241619552.py:28: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n",
      "/var/folders/jw/qw353j7x7h970k1t74h_j5nc0000gn/T/ipykernel_9220/241619552.py:28: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n",
      "/var/folders/jw/qw353j7x7h970k1t74h_j5nc0000gn/T/ipykernel_9220/241619552.py:28: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n",
      "/var/folders/jw/qw353j7x7h970k1t74h_j5nc0000gn/T/ipykernel_9220/241619552.py:28: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(chemin_fichier, sep=sep, encoding=encoding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['usagers_2006.csv', 'usagers_2012.csv', 'usagers_2013.csv', 'usagers_2007.csv', 'usagers_2011.csv', 'usagers_2005.csv', 'usagers_2010.csv', 'usagers_2014.csv', 'usagers_2015.csv', 'usagers_2017.csv', 'usagers_2016.csv', 'usagers_2018.csv', 'usagers_2019.csv', 'usagers_2021.csv', 'usagers_2009.csv', 'usagers_2008.csv', 'usagers_2020.csv', 'usagers_2022.csv']\n",
      "['vehicules_2018.csv', 'vehicules_2019.csv', 'vehicules_2022.csv', 'vehicules_2009.csv', 'vehicules_2021.csv', 'vehicules_2020.csv', 'vehicules_2008.csv', 'vehicules_2005.csv', 'vehicules_2011.csv', 'vehicules_2010.csv', 'vehicules_2012.csv', 'vehicules_2006.csv', 'vehicules_2007.csv', 'vehicules_2013.csv', 'vehicules_2017.csv', 'vehicules_2016.csv', 'vehicules_2014.csv', 'vehicules_2015.csv']\n"
     ]
    }
   ],
   "source": [
    "carac_df = concat_files(\"caracteristiques\")\n",
    "lieux_df = concat_files(\"lieux\")\n",
    "usager_df = concat_files(\"usagers\")\n",
    "vehi_df = concat_files(\"vehicules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
